#!/usr/bin/env python3
"""
LangGraph Client for Astrophysics TAP Query System

è¿™æ˜¯ä¸€ä¸ªLangGraphå®¢æˆ·ç«¯ï¼Œä½¿ç”¨è±†åŒ…APIä½œä¸ºLLMï¼Œé€šè¿‡MCPé€‚é…å™¨ä¸å¤©ä½“ç‰©ç†å­¦TAPæŸ¥è¯¢æœåŠ¡å™¨é€šä¿¡ã€‚
æ”¯æŒè‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·æ‰§è¡ŒæŸ¥è¯¢ã€‚
"""

import asyncio
import logging
import os
import subprocess
import json
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import BaseTool
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    try:
        from langchain_community.chat_models import ChatOpenAI
    except ImportError:
        print("è­¦å‘Š: æ— æ³•å¯¼å…¥ChatOpenAIï¼Œè¯·æ£€æŸ¥langchainå®‰è£…")
        ChatOpenAI = None
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from typing_extensions import TypedDict, Annotated

try:
    from langchain_mcp_adapters.tools import MCPTool, load_mcp_tools
    from mcp.client.session import ClientSession
    from mcp.client.stdio import stdio_client, StdioServerParameters
except ImportError:
    print("è­¦å‘Š: langchain-mcp-adapters æˆ– mcp æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install langchain-mcp-adapters mcp")
    MCPTool = None
    load_mcp_tools = None
    ClientSession = None
    stdio_client = None
    StdioServerParameters = None

# å¯¼å…¥é¡¹ç›®é…ç½®ç³»ç»Ÿ
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from src.config.loader import load_yaml_config


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MCPClientWrapper:
    """MCPå®¢æˆ·ç«¯åŒ…è£…å™¨ï¼Œä½¿ç”¨å­è¿›ç¨‹ç®¡ç†MCPæœåŠ¡å™¨"""
    
    def __init__(self):
        self.server_process = None
        self.tools = []
        self.initialized = False
        
    async def start_server(self):
        """å¯åŠ¨MCPæœåŠ¡å™¨å­è¿›ç¨‹"""
        try:
            # ä½¿ç”¨æ¨¡å—æ–¹å¼å¯åŠ¨MCPæœåŠ¡å™¨
            self.server_process = subprocess.Popen(
                ['python', '-m', 'src.mcp_retrieval.server'],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
            )
            logger.info("MCPæœåŠ¡å™¨å­è¿›ç¨‹å·²å¯åŠ¨")
            
            # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
            await asyncio.sleep(3)
            
            # åˆå§‹åŒ–MCPè¿æ¥
            await self._initialize_connection()
            
            return True
        except Exception as e:
            logger.error(f"å¯åŠ¨MCPæœåŠ¡å™¨å¤±è´¥: {str(e)}")
            return False
    
    async def _initialize_connection(self):
        """åˆå§‹åŒ–MCPè¿æ¥"""
        try:
            # ç®€åŒ–åˆå§‹åŒ– - ä¸å‘é€åˆå§‹åŒ–è¯·æ±‚ï¼Œç›´æ¥æ ‡è®°ä¸ºå·²åˆå§‹åŒ–
            # å› ä¸ºæˆ‘ä»¬çš„MCPæœåŠ¡å™¨ä¸éœ€è¦å¤æ‚çš„åˆå§‹åŒ–æµç¨‹
            self.initialized = True
            logger.info("MCPè¿æ¥åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"MCPè¿æ¥åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def stop_server(self):
        """åœæ­¢MCPæœåŠ¡å™¨å­è¿›ç¨‹"""
        if self.server_process:
            try:
                self.server_process.terminate()
                self.server_process.wait(timeout=5)
                logger.info("MCPæœåŠ¡å™¨å­è¿›ç¨‹å·²åœæ­¢")
            except subprocess.TimeoutExpired:
                self.server_process.kill()
                logger.warning("å¼ºåˆ¶ç»ˆæ­¢MCPæœåŠ¡å™¨å­è¿›ç¨‹")
            except Exception as e:
                logger.error(f"åœæ­¢MCPæœåŠ¡å™¨æ—¶å‡ºé”™: {str(e)}")
    
    async def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:
        """è°ƒç”¨MCPå·¥å…·"""
        try:
            if not self.initialized:
                return "MCPè¿æ¥æœªåˆå§‹åŒ–"
            
            # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºå”¯ä¸€IDï¼Œé¿å…å†²çª
            import time
            request_id = int(time.time() * 1000) % 100000
            
            # æ„å»ºMCPè¯·æ±‚
            request = {
                "jsonrpc": "2.0",
                "id": request_id,
                "method": "tools/call",
                "params": {
                    "name": tool_name,
                    "arguments": arguments
                }
            }
            
            # å‘é€è¯·æ±‚åˆ°MCPæœåŠ¡å™¨
            if self.server_process and self.server_process.stdin:
                request_json = json.dumps(request) + "\n"
                self.server_process.stdin.write(request_json)
                self.server_process.stdin.flush()
                
                # è¯»å–å“åº”
                response_line = self.server_process.stdout.readline()
                if response_line:
                    logger.info(f"ğŸ”§ MCPåŸå§‹å“åº”: {response_line.strip()}")
                    response = json.loads(response_line.strip())
                    logger.info(f"ğŸ”§ MCPè§£æå“åº”: {response}")
                    if "result" in response:
                        # å¤„ç†MCPå·¥å…·è°ƒç”¨ç»“æœ
                        result = response["result"]
                        logger.info(f"ğŸ”§ MCPç»“æœ: {result}")
                        if "content" in result and isinstance(result["content"], list) and len(result["content"]) > 0:
                            # æå–æ–‡æœ¬å†…å®¹
                            content = result["content"][0].get("text", str(result))
                            logger.info(f"ğŸ”§ æå–å†…å®¹: {content[:200]}...")
                            return content
                        else:
                            logger.info(f"ğŸ”§ ç›´æ¥è¿”å›ç»“æœ: {str(result)}")
                            return str(result)
                    elif "error" in response:
                        logger.error(f"âŒ MCPé”™è¯¯: {response['error']}")
                        return f"é”™è¯¯: {response['error']}"
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥å“åº”æ ¼å¼: {response}")
                        return "æœªçŸ¥å“åº”æ ¼å¼"
                else:
                    logger.warning("âš ï¸ æ— å“åº”")
                    return "æ— å“åº”"
            else:
                return "MCPæœåŠ¡å™¨æœªè¿è¡Œ"
                
        except Exception as e:
            logger.error(f"è°ƒç”¨MCPå·¥å…·å¤±è´¥: {str(e)}")
            return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def get_available_tools(self) -> List[str]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return [
            "get_object_by_identifier",
            "get_bibliographic_data", 
            "search_objects_by_coordinates"
        ]

class State(TypedDict):
    """å›¾çŠ¶æ€å®šä¹‰"""
    messages: Annotated[List, add_messages]
    user_query: str
    selected_tools: List[str]
    query_results: Dict[str, Any]
    final_response: str

class AstrophysicsQueryClient:
    """
    å¤©ä½“ç‰©ç†å­¦æŸ¥è¯¢å®¢æˆ·ç«¯
    
    ä½¿ç”¨LangGraphæ„å»ºæŸ¥è¯¢æµç¨‹ï¼Œé›†æˆè±†åŒ…APIå’ŒMCPå·¥å…·
    """
    
    def __init__(self, use_mcp=True):
        logger.info("ğŸ—ï¸ åˆå§‹åŒ–å¤©ä½“ç‰©ç†å­¦æŸ¥è¯¢å®¢æˆ·ç«¯...")
        self.llm = None
        self.mcp_tools = []
        self.graph = None
        self.mcp_session = None
        self.mcp_read = None
        self.mcp_write = None
        self.use_mcp = use_mcp
        self.mcp_available = False
        
        self._setup_llm()
        # ä¸åœ¨è¿™é‡Œè®¾ç½®å·¥å…·ï¼Œç­‰MCPåˆå§‹åŒ–å®Œæˆåå†è®¾ç½®
        self._build_graph()
        
        logger.info("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize_mcp(self):
        """å¼‚æ­¥åˆå§‹åŒ–MCPå·¥å…·"""
        if self.use_mcp:
            logger.info("ğŸ”— å°è¯•åˆå§‹åŒ–MCPè¿æ¥...")
            try:
                await self._setup_mcp_tools()
                self.mcp_available = True
                logger.info("âœ… MCPè¿æ¥æˆåŠŸï¼Œä½¿ç”¨MCPå·¥å…·")
            except Exception as e:
                logger.warning(f"âš ï¸ MCPè¿æ¥å¤±è´¥: {str(e)}")
                logger.info("ğŸ”„ å›é€€åˆ°ç›´æ¥è°ƒç”¨å·¥å…·æ¨¡å¼")
                self.mcp_available = False
                self._setup_mock_tools()
        else:
            logger.info("ğŸ”§ ä½¿ç”¨ç›´æ¥è°ƒç”¨å·¥å…·æ¨¡å¼")
            self.mcp_available = False
            self._setup_mock_tools()
        
        # é‡æ–°æ„å»ºå›¾ä»¥ä½¿ç”¨å½“å‰å·¥å…·
        self._build_graph()

    def _setup_llm(self):
        """è®¾ç½®è±†åŒ…API LLM"""
        try:
            # ä»conf.yamlåŠ è½½é…ç½®
            config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'conf.yaml')
            conf = load_yaml_config(config_path)
            basic_model_conf = conf.get('BASIC_MODEL', {})

            # è·å–è±†åŒ…APIé…ç½®
            api_key = basic_model_conf.get('api_key')
            base_url = basic_model_conf.get('base_url', 'https://ark.cn-beijing.volces.com/api/v3')
            model = basic_model_conf.get('model', 'doubao-pro-4k')

            if not api_key:
                raise ValueError("è¯·åœ¨conf.yamlæ–‡ä»¶ä¸­è®¾ç½®BASIC_MODEL.api_key")

            # ä½¿ç”¨OpenAIå…¼å®¹æ¥å£è¿æ¥è±†åŒ…ï¼Œå¹¶ç»‘å®šå·¥å…·
            self.llm = ChatOpenAI(
                model=model,
                openai_api_key=api_key,
                openai_api_base=base_url,
                temperature=0.1,
                max_tokens=2000
            )
            logger.info(f"è±†åŒ…API LLM åˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: {model}, åŸºç¡€URL: {base_url}")

        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def _setup_mcp_tools(self):
        """è®¾ç½®MCPå·¥å…·é€‚é…å™¨"""
        # åˆ›å»ºMCPå®¢æˆ·ç«¯åŒ…è£…å™¨å®ä¾‹
        self.mcp_client = MCPClientWrapper()
        
        # å¯åŠ¨MCPæœåŠ¡å™¨
        logger.info("æ­£åœ¨å¯åŠ¨MCPæœåŠ¡å™¨...")
        if not await self.mcp_client.start_server():
            raise Exception("MCPæœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
        
        logger.info("MCPæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ")
        
        # åˆ›å»ºMCPå·¥å…·åŒ…è£…å™¨
        from langchain_core.tools import tool
        
        @tool
        def get_object_by_identifier_mcp(object_id: str) -> str:
            """æ ¹æ®å¤©ä½“æ ‡è¯†ç¬¦è·å–åŸºç¡€ä¿¡æ¯ (ç›´æ¥è°ƒç”¨ç‰ˆæœ¬)"""
            try:
                # ç›´æ¥è°ƒç”¨tools.pyä¸­çš„å‡½æ•°ï¼Œç»•è¿‡MCPé€šä¿¡
                from .tools import get_object_by_identifier
                result = get_object_by_identifier(object_id)
                return str(result)
            except Exception as e:
                logger.error(f"å¤©ä½“æŸ¥è¯¢å¤±è´¥: {str(e)}")
                return f"å¤©ä½“æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
        @tool
        def get_bibliographic_data_mcp(object_id: str) -> str:
            """è·å–å¤©ä½“çš„å‚è€ƒæ–‡çŒ®ä¿¡æ¯ (ç›´æ¥è°ƒç”¨ç‰ˆæœ¬)"""
            try:
                # ç›´æ¥è°ƒç”¨tools.pyä¸­çš„å‡½æ•°ï¼Œç»•è¿‡MCPé€šä¿¡
                from .tools import get_bibliographic_data
                result = get_bibliographic_data(object_id)
                return str(result)
            except Exception as e:
                logger.error(f"æ–‡çŒ®æŸ¥è¯¢å¤±è´¥: {str(e)}")
                return f"æ–‡çŒ®æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
        @tool
        def search_objects_by_coordinates_mcp(ra: float, dec: float, radius: float = 0.1) -> str:
            """æ ¹æ®åæ ‡æœç´¢é™„è¿‘çš„å¤©ä½“ (ç›´æ¥è°ƒç”¨ç‰ˆæœ¬)"""
            try:
                # ç›´æ¥è°ƒç”¨tools.pyä¸­çš„å‡½æ•°ï¼Œç»•è¿‡MCPé€šä¿¡
                from .tools import search_objects_by_coordinates
                result = search_objects_by_coordinates(ra, dec, radius)
                return str(result)
            except Exception as e:
                logger.error(f"åæ ‡æœç´¢å¤±è´¥: {str(e)}")
                return f"åæ ‡æœç´¢å¤±è´¥: {str(e)}"
        
        self.mcp_tools = [
            get_object_by_identifier_mcp,
            get_bibliographic_data_mcp,
            search_objects_by_coordinates_mcp
        ]
        
        logger.info(f"æˆåŠŸåˆ›å»º {len(self.mcp_tools)} ä¸ªMCPå·¥å…·")
    
    def _setup_mock_tools(self):
        """è®¾ç½®ç›´æ¥è°ƒç”¨å·¥å…·ï¼ˆç›´æ¥è°ƒç”¨tools.pyä¸­çš„å‡½æ•°ï¼Œä¸ä½¿ç”¨MCPæœåŠ¡å™¨ï¼‰"""
        from langchain_core.tools import tool
        from .tools import get_object_by_identifier as _get_object_by_identifier
        from .tools import get_bibliographic_data as _get_bibliographic_data
        from .tools import search_objects_by_coordinates as _search_objects_by_coordinates
        
        @tool
        def get_object_by_identifier(object_id: str) -> str:
            """
            æ ¹æ®å¤©ä½“æ ‡è¯†ç¬¦è·å–åŸºç¡€å¤©æ–‡æ•°æ®
            
            è¿™ä¸ªå·¥å…·ç”¨äºæŸ¥è¯¢å¤©ä½“çš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
            - å¤©ä½“åæ ‡ï¼ˆèµ¤ç»ã€èµ¤çº¬ï¼‰
            - ä¸»è¦æ ‡è¯†ç¬¦
            - è§†å·®å’Œå¾„å‘é€Ÿåº¦
            - æ˜Ÿç³»å°ºå¯¸å’Œè§’åº¦
            - å‚è€ƒæ–‡çŒ®æ•°é‡
            
            å‚æ•°:
                object_id (str): å¤©ä½“æ ‡è¯†ç¬¦ï¼Œå¦‚ 'M13', 'NGC 6205', 'Vega', 'Sirius' ç­‰
            
            è¿”å›:
                str: åŒ…å«å¤©ä½“åŸºç¡€ä¿¡æ¯çš„JSONæ ¼å¼å­—ç¬¦ä¸²
            
            ä½¿ç”¨åœºæ™¯:
            - ç”¨æˆ·è¯¢é—®å¤©ä½“çš„åŸºæœ¬ä¿¡æ¯
            - éœ€è¦è·å–å¤©ä½“çš„åæ ‡å’Œç‰©ç†å‚æ•°
            - æŸ¥è¯¢ç‰¹å®šå¤©ä½“çš„åŸºæœ¬å±æ€§
            """
            try:
                result = _get_object_by_identifier(object_id)
                return str(result)
            except Exception as e:
                return f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
        @tool
        def get_bibliographic_data(object_id: str) -> str:
            """
            æ ¹æ®å¤©ä½“æ ‡è¯†ç¬¦è·å–ç›¸å…³çš„å‚è€ƒæ–‡çŒ®å’Œå­¦æœ¯è®ºæ–‡
            
            è¿™ä¸ªå·¥å…·ç”¨äºæŸ¥è¯¢ä¸ç‰¹å®šå¤©ä½“ç›¸å…³çš„ç ”ç©¶æ–‡çŒ®ï¼ŒåŒ…æ‹¬ï¼š
            - è®ºæ–‡çš„BibCodeæ ‡è¯†ç¬¦
            - æœŸåˆŠåç§°
            - è®ºæ–‡æ ‡é¢˜
            - å‘è¡¨å¹´ä»½
            - å·å·å’Œé¡µç 
            - DOIé“¾æ¥
            
            å‚æ•°:
                object_id (str): å¤©ä½“æ ‡è¯†ç¬¦ï¼Œå¦‚ 'M13', 'NGC 6205', 'Vega' ç­‰
            
            è¿”å›:
                str: åŒ…å«å‚è€ƒæ–‡çŒ®åˆ—è¡¨çš„JSONæ ¼å¼å­—ç¬¦ä¸²
            
            ä½¿ç”¨åœºæ™¯:
            - ç”¨æˆ·è¯¢é—®å¤©ä½“çš„ç ”ç©¶æ–‡çŒ®
            - éœ€è¦æŸ¥æ‰¾ç›¸å…³çš„å­¦æœ¯è®ºæ–‡
            - äº†è§£å¤©ä½“çš„ç ”ç©¶å†å²
            """
            try:
                result = _get_bibliographic_data(object_id)
                return str(result)
            except Exception as e:
                return f"æ–‡çŒ®æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
        @tool
        def search_objects_by_coordinates(ra: float, dec: float, radius: float = 0.1) -> str:
            """
            æ ¹æ®å¤©çƒåæ ‡æœç´¢é™„è¿‘çš„å¤©ä½“å¯¹è±¡
            
            è¿™ä¸ªå·¥å…·ç”¨äºåœ¨æŒ‡å®šåæ ‡å‘¨å›´æœç´¢å¤©ä½“ï¼ŒåŒ…æ‹¬ï¼š
            - æœç´¢ä¸­å¿ƒåæ ‡ï¼ˆèµ¤ç»ã€èµ¤çº¬ï¼‰
            - æœç´¢åŠå¾„
            - æ‰¾åˆ°çš„å¤©ä½“åˆ—è¡¨
            - æ¯ä¸ªå¤©ä½“çš„è·ç¦»å’Œç±»å‹
            
            å‚æ•°:
                ra (float): èµ¤ç»åæ ‡ï¼ˆåº¦ï¼‰ï¼ŒèŒƒå›´0-360
                dec (float): èµ¤çº¬åæ ‡ï¼ˆåº¦ï¼‰ï¼ŒèŒƒå›´-90åˆ°90
                radius (float): æœç´¢åŠå¾„ï¼ˆåº¦ï¼‰ï¼Œé»˜è®¤0.1åº¦
            
            è¿”å›:
                str: åŒ…å«æœç´¢ç»“æœçš„JSONæ ¼å¼å­—ç¬¦ä¸²
            
            ä½¿ç”¨åœºæ™¯:
            - ç”¨æˆ·æä¾›åæ ‡éœ€è¦æœç´¢é™„è¿‘å¤©ä½“
            - éœ€è¦äº†è§£æŸä¸ªåŒºåŸŸçš„å¤©ä½“åˆ†å¸ƒ
            - å¯»æ‰¾ç‰¹å®šåæ ‡é™„è¿‘çš„å¤©ä½“å¯¹è±¡
            """
            try:
                result = _search_objects_by_coordinates(ra, dec, radius)
                return str(result)
            except Exception as e:
                return f"åæ ‡æœç´¢å¤±è´¥: {str(e)}"
        
        self.mcp_tools = [get_object_by_identifier, get_bibliographic_data, search_objects_by_coordinates]
        logger.info(f"ç›´æ¥è°ƒç”¨å·¥å…·è®¾ç½®å®Œæˆï¼Œå·¥å…·æ•°é‡: {len(self.mcp_tools)}")
        logger.info(f"å·¥å…·åç§°: {[tool.name for tool in self.mcp_tools]}")
    
    def _build_graph(self):
        """æ„å»ºLangGraphæŸ¥è¯¢æµç¨‹"""
        # åˆ›å»ºå·¥å…·èŠ‚ç‚¹
        tool_node = ToolNode(self.mcp_tools)
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(State)
        
        # æ·»åŠ èŠ‚ç‚¹ - åŒ…å«å“åº”ç”Ÿæˆ
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", tool_node)
        workflow.add_node("response", self._generate_response)
        
        # è®¾ç½®è¾¹ - å®Œæ•´çš„å·¥ä½œæµ
        workflow.set_entry_point("agent")
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "continue": "tools",
                "end": "response"
            }
        )
        workflow.add_conditional_edges(
            "tools",
            self._should_continue,
            {
                "continue": "agent",
                "end": "response"
            }
        )
        workflow.add_edge("response", END)
        
        # ç¼–è¯‘å›¾
        self.graph = workflow.compile()
        logger.info("LangGraph æŸ¥è¯¢æµç¨‹æ„å»ºå®Œæˆ")
    
    async def _agent_node(self, state: State) -> State:
        """æ™ºèƒ½ä»£ç†èŠ‚ç‚¹ - è®©LLMè‡ªå·±é€‰æ‹©å·¥å…·"""
        messages = state["messages"]
        
        # æ„å»ºç³»ç»Ÿæç¤ºï¼Œè®©LLMäº†è§£å¯ç”¨çš„å·¥å…·
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©ä½“ç‰©ç†å­¦åŠ©æ‰‹ï¼Œå¯ä»¥è®¿é—®ä»¥ä¸‹å·¥å…·æ¥æŸ¥è¯¢å¤©ä½“æ•°æ®ï¼š

1. get_object_by_identifier(object_id: str) - è·å–å¤©ä½“çš„åŸºç¡€ä¿¡æ¯
   - ç”¨äºæŸ¥è¯¢å¤©ä½“çš„åæ ‡ã€è§†å·®ã€å¾„å‘é€Ÿåº¦ç­‰åŸºæœ¬å‚æ•°
   - é€‚ç”¨äºï¼šè¯¢é—®å¤©ä½“åŸºæœ¬ä¿¡æ¯ã€åæ ‡ã€ç‰©ç†å‚æ•°ç­‰
   - å‚æ•°æå–ï¼šä»æŸ¥è¯¢ä¸­è¯†åˆ«å¤©ä½“æ ‡è¯†ç¬¦ï¼Œå¦‚M31ã€M13ã€NGC6205ç­‰

2. get_bibliographic_data(object_id: str) - è·å–å¤©ä½“çš„å‚è€ƒæ–‡çŒ®
   - ç”¨äºæŸ¥è¯¢ä¸å¤©ä½“ç›¸å…³çš„ç ”ç©¶è®ºæ–‡å’Œå­¦æœ¯æ–‡çŒ®
   - é€‚ç”¨äºï¼šè¯¢é—®ç ”ç©¶æ–‡çŒ®ã€å­¦æœ¯è®ºæ–‡ã€ç ”ç©¶å†å²ç­‰
   - å‚æ•°æå–ï¼šä»æŸ¥è¯¢ä¸­è¯†åˆ«å¤©ä½“æ ‡è¯†ç¬¦ï¼Œå¦‚M31ã€M13ã€NGC6205ç­‰

3. search_objects_by_coordinates(ra: float, dec: float, radius: float) - åæ ‡æœç´¢
   - ç”¨äºåœ¨æŒ‡å®šåæ ‡å‘¨å›´æœç´¢å¤©ä½“
   - é€‚ç”¨äºï¼šæä¾›åæ ‡æœç´¢å¤©ä½“ã€äº†è§£åŒºåŸŸå¤©ä½“åˆ†å¸ƒç­‰

é‡è¦æç¤ºï¼š
- å½“ç”¨æˆ·æåˆ°"M31"ã€"M13"ã€"NGC"ç­‰å¤©ä½“æ ‡è¯†ç¬¦æ—¶ï¼Œç›´æ¥ä½¿ç”¨è¿™äº›æ ‡è¯†ç¬¦ä½œä¸ºobject_idå‚æ•°
- å½“ç”¨æˆ·è¯¢é—®"è®ºæ–‡"ã€"æ–‡çŒ®"ã€"æ£€ç´¢"æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨get_bibliographic_dataå·¥å…·
- ç¡®ä¿ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æ­£ç¡®æå–å¤©ä½“æ ‡è¯†ç¬¦

è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å¹¶è°ƒç”¨ã€‚å¦‚æœéœ€è¦å¤šä¸ªå·¥å…·ï¼Œå¯ä»¥ä¾æ¬¡è°ƒç”¨ã€‚

"""
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if not messages or not isinstance(messages[0], SystemMessage):
            messages = [SystemMessage(content=system_prompt)] + messages
        
        try:
            # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥å·¥å…·åˆ—è¡¨
            logger.info(f"ğŸ”§ å¯ç”¨å·¥å…·æ•°é‡: {len(self.mcp_tools)}")
            if self.mcp_tools:
                logger.info(f"ğŸ”§ å·¥å…·åˆ—è¡¨: {[tool.name for tool in self.mcp_tools]}")
            else:
                logger.warning("âš ï¸ å·¥å…·åˆ—è¡¨ä¸ºç©ºï¼")
            
            # ç»‘å®šå·¥å…·åˆ°LLMå¹¶è°ƒç”¨
            llm_with_tools = self.llm.bind_tools(self.mcp_tools)
            response = await llm_with_tools.ainvoke(messages)
            messages.append(response)
            
            # è®°å½•å·¥å…·é€‰æ‹©ä¿¡æ¯
            if hasattr(response, 'tool_calls') and response.tool_calls:
                logger.info(f"ğŸ”§ é€‰æ‹©å·¥å…·: {[tool_call['name'] for tool_call in response.tool_calls]}")
            else:
                logger.info("ğŸ“ ç›´æ¥è¿”å›æ–‡æœ¬å“åº”")
                logger.info(f"ğŸ“ å“åº”å†…å®¹: {response.content[:200]}...")
            
            state["messages"] = messages
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½ä»£ç†èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
            error_message = AIMessage(content=f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºç°é”™è¯¯: {str(e)}")
            messages.append(error_message)
            state["messages"] = messages
        
        return state
    
    def _should_continue(self, state: State) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œå·¥å…·"""
        messages = state["messages"]
        last_message = messages[-1]
        
        # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯åŒ…å«å·¥å…·è°ƒç”¨ï¼Œåˆ™ç»§ç»­åˆ°å·¥å…·èŠ‚ç‚¹
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "continue"
        else:
            # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å·¥å…·ç»“æœï¼Œåˆ™è½¬åˆ°å“åº”ç”ŸæˆèŠ‚ç‚¹
            if hasattr(last_message, 'content') and last_message.content:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·ç»“æœï¼ˆé€šå¸¸åŒ…å«JSONæ ¼å¼çš„æ•°æ®ï¼‰
                content = last_message.content
                if isinstance(content, str) and ('{' in content and '}' in content):
                    return "end"  # è½¬åˆ°responseèŠ‚ç‚¹
                else:
                    # ç›´æ¥æ–‡æœ¬å“åº”ï¼Œè®¾ç½®æœ€ç»ˆå“åº”
                    state["final_response"] = content
                    return "end"
            else:
                state["final_response"] = "æŸ¥è¯¢å®Œæˆï¼Œä½†æ²¡æœ‰è¿”å›ç»“æœ"
                return "end"
    
    async def _analyze_query(self, state: State) -> State:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢"""
        user_query = state["user_query"]
        
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªå¤©ä½“ç‰©ç†å­¦æŸ¥è¯¢åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾ï¼Œç¡®å®šéœ€è¦ä»€ä¹ˆç±»å‹çš„å¤©æ–‡æ•°æ®ã€‚

å¯ç”¨çš„æŸ¥è¯¢ç±»å‹ï¼š
1. åŸºç¡€ä¿¡æ¯æŸ¥è¯¢ - è·å–å¤©ä½“çš„åæ ‡ã€è§†å·®ã€å¾„å‘é€Ÿåº¦ç­‰åŸºæœ¬å‚æ•°
2. æ–‡çŒ®æŸ¥è¯¢ - è·å–ä¸å¤©ä½“ç›¸å…³çš„ç ”ç©¶è®ºæ–‡å’Œå‚è€ƒæ–‡çŒ®
3. åæ ‡æœç´¢ - æ ¹æ®å¤©çƒåæ ‡æœç´¢é™„è¿‘çš„å¤©ä½“

è¯·ç®€è¦åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æ„å›¾ã€‚
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        ]
        
        try:
            response = await self.llm.ainvoke(messages)
            analysis = response.content
            
            state["messages"].append(AIMessage(content=f"æŸ¥è¯¢åˆ†æ: {analysis}"))
            logger.info(f"æŸ¥è¯¢åˆ†æå®Œæˆ: {analysis[:100]}...")
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}")
            state["messages"].append(AIMessage(content=f"æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}"))
        
        return state
    
    async def _select_tools(self, state: State) -> State:
        """é€‰æ‹©åˆé€‚çš„å·¥å…·"""
        user_query = state["user_query"]
        
        # å·¥å…·é€‰æ‹©é€»è¾‘
        selected_tools = []
        query_lower = user_query.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤©ä½“åç§°æˆ–æ ‡è¯†ç¬¦
        if any(keyword in query_lower for keyword in ['m13', 'm31', 'ngc', 'vega', 'sirius', 'basic info', 'information']):
            selected_tools.append("get_object_by_identifier")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–‡çŒ®ä¿¡æ¯
        if any(keyword in query_lower for keyword in ['reference', 'paper', 'bibliography', 'literature', 'publication', 'è®ºæ–‡', 'æ–‡çŒ®', 'æ£€ç´¢']):
            selected_tools.append("get_bibliographic_data")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åæ ‡æœç´¢
        if any(keyword in query_lower for keyword in ['coordinate', 'ra', 'dec', 'search', 'nearby']):
            selected_tools.append("search_objects_by_coordinates")
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®åŒ¹é…ï¼Œé»˜è®¤ä½¿ç”¨åŸºç¡€ä¿¡æ¯æŸ¥è¯¢
        if not selected_tools:
            selected_tools.append("get_object_by_identifier")
        
        state["selected_tools"] = selected_tools
        logger.info(f"é€‰æ‹©çš„å·¥å…·: {selected_tools}")
        
        return state
    
    async def _generate_response(self, state: State) -> State:
        """ç”Ÿæˆæœ€ç»ˆå“åº”"""
        user_query = state["user_query"]
        messages = state["messages"]
        
        # ä»æ¶ˆæ¯ä¸­æå–å·¥å…·ç»“æœ
        tool_results = {}
        for message in messages:
            if hasattr(message, 'tool_calls') and message.tool_calls:
                # è¿™æ˜¯å·¥å…·è°ƒç”¨æ¶ˆæ¯
                for tool_call in message.tool_calls:
                    tool_name = tool_call['name']
                    tool_args = tool_call.get('args', {})
            elif hasattr(message, 'content') and message.content:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·ç»“æœæ¶ˆæ¯
                content = message.content
                if isinstance(content, str) and ('{' in content and '}' in content):
                    try:
                        import json
                        # å°è¯•è§£æJSONæ ¼å¼çš„å·¥å…·ç»“æœ
                        if content.startswith('{') and content.endswith('}'):
                            result_data = json.loads(content)
                            if isinstance(result_data, dict) and ('success' in result_data or 'references' in result_data):
                                tool_results['tool_result'] = result_data
                    except:
                        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œä¹Ÿä¿å­˜åŸå§‹å†…å®¹
                        tool_results['tool_result'] = content
        
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©ä½“ç‰©ç†å­¦åŠ©æ‰‹ã€‚åŸºäºå·¥å…·æŸ¥è¯¢çš„ç»“æœï¼Œä¸ºç”¨æˆ·æä¾›æ¸…æ™°ã€å‡†ç¡®çš„å›ç­”ã€‚

é‡è¦è¦æ±‚ï¼š
1. å¿…é¡»ä½¿ç”¨å·¥å…·è¿”å›çš„çœŸå®æ•°æ®ï¼Œä¸è¦ç”Ÿæˆè™šå‡æˆ–æ¨¡æ‹Ÿçš„å†…å®¹
2. å¦‚æœå·¥å…·è¿”å›äº†å…·ä½“çš„è®ºæ–‡æ•°æ®ï¼Œç›´æ¥å±•ç¤ºè¿™äº›çœŸå®çš„è®ºæ–‡ä¿¡æ¯
3. å¦‚æœå·¥å…·è¿”å›äº†å¤©ä½“æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨è¿™äº›çœŸå®çš„å¤©æ–‡æ•°æ®
4. ä¸è¦åŸºäºå¸¸è¯†ç”Ÿæˆå†…å®¹ï¼Œåªä½¿ç”¨å·¥å…·æŸ¥è¯¢çš„å®é™…ç»“æœ
5. å¦‚æœå·¥å…·æ²¡æœ‰è¿”å›æ•°æ®ï¼Œæ˜ç¡®è¯´æ˜"æœªæ‰¾åˆ°ç›¸å…³æ•°æ®"

æ•°æ®å¤„ç†è§„åˆ™ï¼š
- å¦‚æœå·¥å…·è¿”å›åŒ…å«'references'å­—æ®µï¼Œè¯´æ˜æ‰¾åˆ°äº†è®ºæ–‡æ•°æ®ï¼Œå¿…é¡»å±•ç¤ºè¿™äº›çœŸå®è®ºæ–‡
- å¦‚æœå·¥å…·è¿”å›åŒ…å«'success': Trueï¼Œè¯´æ˜æŸ¥è¯¢æˆåŠŸï¼Œå¿…é¡»ä½¿ç”¨è¿”å›çš„æ•°æ®
- å¦‚æœå·¥å…·è¿”å›åŒ…å«'data'å­—æ®µï¼Œè¯´æ˜æ‰¾åˆ°äº†å¤©ä½“æ•°æ®ï¼Œå¿…é¡»ä½¿ç”¨è¿™äº›æ•°æ®

è¯·ï¼š
1. æ€»ç»“æŸ¥è¯¢ç»“æœçš„å…³é”®ä¿¡æ¯
2. ç”¨ä¸“ä¸šä¸¥è°¨çš„è¯­è¨€è§£é‡Šå¤©æ–‡æ•°æ®
3. å¦‚æœæœ‰å¤šä¸ªç»“æœï¼Œè¿›è¡Œé€‚å½“çš„ç»„ç»‡å’Œåˆ†ç±»
4. ä¿æŒç§‘å­¦ä¸¥è°¨æ€§çš„åŒæ—¶ï¼Œç¡®ä¿å¯è¯»æ€§
5. å§‹ç»ˆåŸºäºå·¥å…·è¿”å›çš„çœŸå®æ•°æ®
6. å¦‚æœæ‰¾åˆ°äº†è®ºæ–‡ï¼Œå¿…é¡»åˆ—å‡ºå…·ä½“çš„è®ºæ–‡æ ‡é¢˜ã€æœŸåˆŠã€å¹´ä»½ç­‰ä¿¡æ¯
"""
        
        # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„æ¶ˆæ¯
        context = f"ç”¨æˆ·æŸ¥è¯¢: {user_query}\n\nå·¥å…·æŸ¥è¯¢ç»“æœ:\n"
        for tool_name, result in tool_results.items():
            context += f"\n{tool_name}: {result}\n"
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=context)
        ]
        
        try:
            response = await self.llm.ainvoke(messages)
            final_response = response.content
            
            state["final_response"] = final_response
            state["messages"].append(AIMessage(content=final_response))
            logger.info("æœ€ç»ˆå“åº”ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            logger.error(f"å“åº”ç”Ÿæˆå¤±è´¥: {str(e)}")
            error_response = f"æŠ±æ­‰ï¼Œå“åº”ç”Ÿæˆæ—¶å‡ºç°é”™è¯¯: {str(e)}"
            state["final_response"] = error_response
            state["messages"].append(AIMessage(content=error_response))
        
        return state
    
    async def query(self, user_input: str) -> str:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        logger.info(f"ğŸš€ æ‰§è¡ŒæŸ¥è¯¢: {user_input}")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "user_query": user_input,
            "selected_tools": [],
            "query_results": {},
            "final_response": ""
        }
        
        try:
            # æ‰§è¡Œå›¾æµç¨‹ï¼Œè®¾ç½®é€’å½’é™åˆ¶
            config = {"recursion_limit": 5}
            result = await self.graph.ainvoke(initial_state, config=config)
            
            # å¦‚æœæ²¡æœ‰final_responseï¼Œä»æœ€åä¸€æ¡æ¶ˆæ¯ä¸­è·å–
            if not result.get("final_response"):
                messages = result.get("messages", [])
                if messages:
                    last_message = messages[-1]
                    if hasattr(last_message, 'content') and last_message.content:
                        result["final_response"] = last_message.content
            
            final_response = result.get("final_response", "æŸ¥è¯¢å®Œæˆï¼Œä½†æ²¡æœ‰è¿”å›ç»“æœ")
            logger.info("âœ… æŸ¥è¯¢å®Œæˆ")
            
            return final_response
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    def query_sync(self, user_input: str) -> str:
        """åŒæ­¥æŸ¥è¯¢æ¥å£"""
        # å…ˆåˆå§‹åŒ–MCPå·¥å…·
        asyncio.run(self.initialize_mcp())
        return asyncio.run(self.query(user_input))
    
    async def close(self):
        """å…³é—­MCPè¿æ¥"""
        if hasattr(self, 'mcp_client') and self.mcp_client:
            try:
                await self.mcp_client.stop_server()
                logger.info("MCPæœåŠ¡å™¨å·²å…³é—­")
            except Exception as e:
                logger.error(f"å…³é—­MCPæœåŠ¡å™¨æ—¶å‡ºé”™: {str(e)}")

async def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼æŸ¥è¯¢ç•Œé¢"""
    print("=" * 60)
    print("ğŸŒŸ å¤©ä½“ç‰©ç†å­¦TAPæŸ¥è¯¢ç³»ç»Ÿ - LangGraphå®¢æˆ·ç«¯")
    print("=" * 60)
    print("æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:")
    print("1. å¤©ä½“åŸºç¡€ä¿¡æ¯: 'Give me basic info about M13'")
    print("2. å‚è€ƒæ–‡çŒ®: 'Find references for Vega'")
    print("3. åæ ‡æœç´¢: 'Search objects near RA=250.4, DEC=36.5'")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("=" * 60)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    try:
        client = AstrophysicsQueryClient()
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–MCPè¿æ¥
        print("ğŸ”— æ­£åœ¨åˆå§‹åŒ–MCPè¿æ¥...")
        await client.initialize_mcp()
        
        if client.mcp_available:
            print("âœ… MCPè¿æ¥æˆåŠŸï¼Œä½¿ç”¨MCPå·¥å…·")
        else:
            print("âš ï¸ ä½¿ç”¨ç›´æ¥è°ƒç”¨å·¥å…·æ¨¡å¼")
            
    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return
    
    # äº¤äº’å¾ªç¯
    try:
        while True:
            try:
                user_input = input("\nğŸ” è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if not user_input:
                    continue
                
                print("\nâ³ æ­£åœ¨å¤„ç†æŸ¥è¯¢...")
                response = await client.query(user_input)
                
                print("\nğŸ“‹ æŸ¥è¯¢ç»“æœ:")
                print("-" * 40)
                print(response)
                print("-" * 40)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ æŸ¥è¯¢å‡ºé”™: {str(e)}")
    finally:
        # ç¡®ä¿å…³é—­MCPè¿æ¥
        await client.close()


def create_client():
    """åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹ - ç”¨äºéäº¤äº’å¼è°ƒç”¨"""
    try:
        return AstrophysicsQueryClient()
    except Exception as e:
        logger.error(f"å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {str(e)}")
        raise


def query_astro_data(user_input: str) -> str:
    """
    åŒæ­¥æŸ¥è¯¢æ¥å£ - ç”¨äºé›†æˆåˆ°å…¶ä»–æ¨¡å—

    Args:
        user_input: ç”¨æˆ·æŸ¥è¯¢è¾“å…¥

    Returns:
        str: æŸ¥è¯¢ç»“æœ
    """
    try:
        client = create_client()
        return client.query_sync(user_input)
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        return f"æ•°æ®æ£€ç´¢å¤±è´¥: {str(e)}"


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œé”™è¯¯: {str(e)}")