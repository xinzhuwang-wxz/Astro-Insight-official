# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

import time
import uuid
from pathlib import Path
from typing import Dict, Any, List, Optional

from .types import (
    ExplainerState, ExplainerRequest, ExplainerResult, CoderOutput,
    ExplanationStatus, ExplanationComplexity, ImageInfo, VLMResponse
)
from .vlm_client import VLMClient
from .prompts import ExplanationPrompts
from .dialogue_manager import DialogueManager


class ExplainerAgent:
    """æ•°æ®å¯è§†åŒ–è§£é‡Šå™¨Agent"""
    
    def __init__(self, output_dir: str = "output"):
        self.vlm_client = VLMClient()
        self.prompts = ExplanationPrompts()
        self.dialogue_manager = DialogueManager(output_dir)
        self.output_dir = Path(output_dir)
        
        # é…ç½®å‚æ•°
        self.max_retries = 3
        self.default_complexity = ExplanationComplexity.DETAILED
    
    def create_initial_state(self, coder_output: CoderOutput, 
                           explanation_type: ExplanationComplexity = None,
                           focus_aspects: Optional[List[str]] = None,
                           session_id: str = None) -> ExplainerState:
        """åˆ›å»ºåˆå§‹çŠ¶æ€"""
        
        if session_id is None:
            session_id = self.dialogue_manager.create_session_id()
        
        # æ„å»ºè§£é‡Šè¯·æ±‚
        request = ExplainerRequest(
            coder_output=coder_output,
            explanation_type=explanation_type or self.default_complexity,
            focus_aspects=focus_aspects,
            target_audience="ç ”ç©¶äººå‘˜",
            dataset_description=None,  # ç¨åä»æ•°æ®é›†æ–‡ä»¶ä¸­è·å–
            additional_context=None
        )
        
        # å¤„ç†å›¾ç‰‡ä¿¡æ¯
        image_files = coder_output.get("generated_files", [])
        processed_images = []
        pending_images = []
        
        # ä¸ºä¼šè¯åˆ›å»ºç‹¬ç«‹ç›®å½•ï¼Œå¹¶å¤åˆ¶å›¾ç‰‡
        session_media_dir = self.dialogue_manager.dialogue_dir / session_id / "images"
        session_media_dir.mkdir(parents=True, exist_ok=True)
        
        for image_path in image_files:
            if Path(image_path).exists():
                # å¤åˆ¶åˆ°ä¼šè¯ç›®å½•
                target_path = session_media_dir / Path(image_path).name
                try:
                    import shutil
                    shutil.copy2(image_path, target_path)
                    session_image_path = str(target_path)
                except Exception:
                    session_image_path = image_path  # å¤åˆ¶å¤±è´¥åˆ™é€€å›åŸè·¯å¾„
                
                image_info = self._create_image_info(session_image_path)
                processed_images.append(image_info)
                pending_images.append(session_image_path)
        
        return ExplainerState(
            session_id=session_id,
            request=request,
            current_step="initialization",
            processed_images=processed_images,
            pending_images=pending_images,
            analysis_context={},
            vlm_responses=[],
            analysis_results=[],
            explanation_result=None,
            error_info=None,
            retry_count=0,
            max_retries=self.max_retries,
            dialogue_record=None,
            output_file_path=None,
            timestamp=time.time()
        )
    
    def process_explanation_request(self, state: ExplainerState) -> ExplainerState:
        """å¤„ç†è§£é‡Šè¯·æ±‚çš„ä¸»æµç¨‹"""
        try:
            # 1. å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
            state["current_step"] = "context_preparation"
            state = self._prepare_context(state)
            
            if state.get("error_info"):
                return state
            
            # 2. åˆ†æå›¾ç‰‡
            state["current_step"] = "image_analysis"
            state = self._analyze_images(state)
            
            if state.get("error_info"):
                return state
            
            # 3. ç”Ÿæˆè§£é‡Š
            state["current_step"] = "explanation_generation"
            state = self._generate_explanations(state)
            
            if state.get("error_info"):
                return state
            
            # 4. åˆ›å»ºæœ€ç»ˆç»“æœ
            state["current_step"] = "result_creation"
            state = self._create_final_result(state)
            
            # 5. ä¿å­˜å¯¹è¯è®°å½•
            state["current_step"] = "dialogue_saving"
            state = self._save_dialogue(state)
            
            state["current_step"] = "completed"
            return state
            
        except Exception as e:
            state["error_info"] = {
                "type": "processing_error",
                "message": f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                "step": state.get("current_step", "unknown")
            }
            state["current_step"] = "error"
            return state
    
    def _prepare_context(self, state: ExplainerState) -> ExplainerState:
        """å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            request = state["request"]
            coder_output = request["coder_output"]
            
            # è·å–æ•°æ®é›†æè¿°
            dataset_used = coder_output.get("dataset_used")
            if dataset_used:
                dataset_description = self._get_dataset_description(dataset_used)
                request["dataset_description"] = dataset_description
            
            # å‡†å¤‡åˆ†æä¸Šä¸‹æ–‡
            context = {
                "user_input": coder_output.get("user_input", ""),
                "dataset_used": dataset_used,
                "dataset_description": request.get("dataset_description", ""),
                "generated_code": coder_output.get("code", ""),
                "code_summary": self._summarize_code(coder_output.get("code", "")),
                "complexity": coder_output.get("complexity", ""),
                "execution_output": coder_output.get("output", ""),
                "generated_texts": coder_output.get("generated_texts", []),
                "focus_aspects": request.get("focus_aspects", [])
            }
            
            state["analysis_context"] = context
            return state
            
        except Exception as e:
            state["error_info"] = {
                "type": "context_preparation_error",
                "message": f"å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯å¤±è´¥: {str(e)}"
            }
            return state
    
    def _analyze_images(self, state: ExplainerState) -> ExplainerState:
        """åˆ†ææ‰€æœ‰å›¾ç‰‡"""
        try:
            pending_images = state["pending_images"]
            analysis_context = state["analysis_context"]
            explanation_type = state["request"]["explanation_type"]
            
            vlm_responses = []
            
            for image_path in pending_images:
                print(f"ğŸ” æ­£åœ¨åˆ†æå›¾ç‰‡: {Path(image_path).name}")
                
                # ä¸ºè¿™å¼ å›¾ç‰‡å‡†å¤‡ç‰¹å®šçš„ä¸Šä¸‹æ–‡
                image_context = analysis_context.copy()
                image_context["image_name"] = Path(image_path).name
                image_context["image_path"] = image_path
                
                # è·å–é€‚å½“çš„prompt
                prompt = self.prompts.get_explanation_prompt(
                    explanation_type.value, 
                    image_context
                )
                
                # è°ƒç”¨VLMåˆ†æ
                vlm_response = self.vlm_client.analyze_image(
                    image_path, 
                    prompt, 
                    image_context
                )
                
                vlm_responses.append({
                    "image_path": image_path,
                    "image_name": Path(image_path).name,
                    "response": vlm_response,
                    "context": image_context
                })
                
                if not vlm_response["success"]:
                    print(f"âš ï¸ å›¾ç‰‡åˆ†æå¤±è´¥: {vlm_response['error']}")
                else:
                    print(f"âœ… å›¾ç‰‡åˆ†æå®Œæˆ: {Path(image_path).name}")
            
            state["vlm_responses"] = vlm_responses
            return state
            
        except Exception as e:
            state["error_info"] = {
                "type": "image_analysis_error",
                "message": f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
            }
            return state

    def _generate_text_only_explanations(self, state: ExplainerState) -> ExplainerState:
        """æ— å›¾æ¨¡å¼ï¼šåŸºäºæ‰§è¡Œè¾“å‡ºä¸æ–‡æœ¬å·¥ä»¶ç”Ÿæˆè§£é‡Š/æ€»ç»“/æ´å¯Ÿ"""
        try:
            analysis_context = state["analysis_context"]
            text_artifacts = analysis_context.get("generated_texts", [])
            stdout_text = analysis_context.get("execution_output", "")

            # ç»„è£…å¯ä¾›LLMçš„æ–‡æœ¬ä¸Šä¸‹æ–‡
            combined_texts = []
            if stdout_text:
                combined_texts.append(f"[STDOUT]\n{stdout_text}")
            for p in text_artifacts:
                try:
                    content = Path(p).read_text(encoding='utf-8', errors='ignore')
                except Exception:
                    try:
                        content = Path(p).read_text(errors='ignore')
                    except Exception:
                        content = ""
                if content:
                    combined_texts.append(f"[FILE] {Path(p).name}\n{content}")

            # åˆ©ç”¨ prompts ç°æœ‰ç»“æ„ï¼šæ„é€ ä¸€ä¸ªâ€œæ–‡æœ¬è§£é‡Šâ€çš„ prompt
            from .prompts import ExplanationPrompts
            prompts = self.prompts if hasattr(self, 'prompts') else ExplanationPrompts()

            # å¤ç”¨ detailed prompt çš„ç»“æ„ï¼Œä½†åœ¨èƒŒæ™¯ä¿¡æ¯ä¸­ä»…ä½¿ç”¨æ–‡æœ¬æ¥æº
            context_for_prompt = analysis_context.copy()
            context_for_prompt["image_name"] = "æ— å›¾ç‰‡ï¼ˆæ–‡æœ¬æ¨¡å¼ï¼‰"

            base_prompt = prompts.get_explanation_prompt(
                state["request"]["explanation_type"].value,
                context_for_prompt
            )

            text_block = "\n\n## æ–‡æœ¬ææ–™\n" + "\n\n".join(combined_texts[:3])  # æ§é•¿åº¦
            full_prompt = base_prompt + text_block + "\n\nè¯·åŸºäºä¸Šè¿°æ–‡æœ¬ææ–™è¿›è¡Œè§£é‡Šä¸æ€»ç»“ã€‚"

            # é€šè¿‡ VLMClient èµ°åŒä¸€è¯·æ±‚é€šé“ï¼Œä½†ä¸ä¼ å›¾ç‰‡ï¼šä½¿ç”¨ä¸€ä¸ªå†…éƒ¨æ–¹æ³•å®ç° text-only
            explanation_text = self._call_text_model(full_prompt)

            explanations = [{
                "image_path": None,
                "image_name": "æ–‡æœ¬æ¨¡å¼",
                "explanation": explanation_text,
                "processing_time": 0,
                "key_findings": self._extract_key_findings(explanation_text)
            }]

            # æ€»ç»“ä¸æ´å¯Ÿ
            summary_text = self._call_text_model(self.prompts.get_summary_prompt([explanation_text], analysis_context))
            insights = self._parse_insights(self._call_text_model(self.prompts.get_insight_extraction_prompt([explanation_text])))

            state["analysis_results"] = {
                "explanations": explanations,
                "summary": summary_text or "",
                "insights": insights or [],
                "successful_count": 1 if explanation_text else 0,
                "total_count": 0
            }
            return state
        except Exception as e:
            state["error_info"] = {
                "type": "text_only_explanation_error",
                "message": f"æ–‡æœ¬æ¨¡å¼è§£é‡Šå¤±è´¥: {str(e)}"
            }
            return state

    def _call_text_model(self, prompt: str) -> str:
        """è°ƒç”¨çº¯æ–‡æœ¬LLMï¼ˆå€Ÿç”¨ VLMClient çš„ HTTP é€šé“ï¼Œå¦‚æœä¸æ”¯æŒåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰"""
        try:
            # å¦‚æœ Explain API ä»…æ”¯æŒå« image çš„æ¶ˆæ¯ï¼Œè¿™é‡Œé™çº§ä½¿ç”¨ç¬¬ä¸€åŸåˆ™ï¼šå‘é€çº¯ text è¯·æ±‚
            payload = {
                "model": getattr(self.vlm_client, "model", None),
                "messages": [{"role": "user", "content": prompt}]
            }
            resp = self.vlm_client._make_request(payload)  # å¤ç”¨å…¶è¯·æ±‚æ–¹æ³•
            return resp.get("content", "") if resp.get("success") else ""
        except Exception:
            return ""
    
    def _generate_explanations(self, state: ExplainerState) -> ExplainerState:
        """ç”Ÿæˆæœ€ç»ˆè§£é‡Š"""
        try:
            vlm_responses = state["vlm_responses"]
            analysis_context = state["analysis_context"]
            
            # æ— å›¾æ¨¡å¼ï¼šå¦‚æœæ²¡æœ‰ä»»ä½•å›¾ç‰‡å¾…åˆ†æï¼Œåˆ™æ”¹èµ°æ–‡æœ¬æ¨¡å¼
            if not vlm_responses and not state.get("processed_images"):
                return self._generate_text_only_explanations(state)

            # å¤„ç†æ¯ä¸ªå›¾ç‰‡çš„è§£é‡Š
            explanations = []
            successful_explanations = []
            
            for vlm_data in vlm_responses:
                vlm_response = vlm_data["response"]
                
                if vlm_response["success"]:
                    explanation = {
                        "image_path": vlm_data["image_path"],
                        "image_name": vlm_data["image_name"],
                        "explanation": vlm_response["content"],
                        "processing_time": vlm_response["processing_time"],
                        "key_findings": self._extract_key_findings(vlm_response["content"])
                    }
                    explanations.append(explanation)
                    successful_explanations.append(vlm_response["content"])
                else:
                    explanation = {
                        "image_path": vlm_data["image_path"],
                        "image_name": vlm_data["image_name"],
                        "explanation": f"åˆ†æå¤±è´¥: {vlm_response['error']}",
                        "processing_time": 0,
                        "key_findings": []
                    }
                    explanations.append(explanation)
            
            # ç”Ÿæˆæ•´ä½“æ€»ç»“
            if successful_explanations:
                summary_prompt = self.prompts.get_summary_prompt(
                    successful_explanations, 
                    analysis_context
                )
                summary_response = self.vlm_client.analyze_image(
                    vlm_responses[0]["image_path"],  # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡ä½œä¸ºå‚è€ƒ
                    summary_prompt,
                    analysis_context
                )
                
                if summary_response["success"]:
                    summary = summary_response["content"]
                else:
                    summary = "æ— æ³•ç”Ÿæˆæ•´ä½“æ€»ç»“"
                
                # æå–å…³é”®æ´å¯Ÿ
                insights_prompt = self.prompts.get_insight_extraction_prompt(successful_explanations)
                insights_response = self.vlm_client.analyze_image(
                    vlm_responses[0]["image_path"],
                    insights_prompt,
                    analysis_context
                )
                
                if insights_response["success"]:
                    insights = self._parse_insights(insights_response["content"])
                else:
                    insights = ["æ— æ³•æå–å…³é”®æ´å¯Ÿ"]
            else:
                summary = "æ‰€æœ‰å›¾ç‰‡åˆ†æå‡å¤±è´¥"
                insights = []
            
            state["analysis_results"] = {
                "explanations": explanations,
                "summary": summary,
                "insights": insights,
                "successful_count": len(successful_explanations),
                "total_count": len(vlm_responses)
            }
            
            return state
            
        except Exception as e:
            state["error_info"] = {
                "type": "explanation_generation_error",
                "message": f"ç”Ÿæˆè§£é‡Šå¤±è´¥: {str(e)}"
            }
            return state
    
    def _create_final_result(self, state: ExplainerState) -> ExplainerState:
        """åˆ›å»ºæœ€ç»ˆç»“æœ"""
        try:
            analysis_results = state["analysis_results"]
            vlm_responses = state["vlm_responses"]
            start_time = state["timestamp"]
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # è®¡ç®—VLMè°ƒç”¨æ¬¡æ•°
            vlm_calls = len(vlm_responses) + 2  # å›¾ç‰‡åˆ†æ + æ€»ç»“ + æ´å¯Ÿæå–
            
            # æ”¶é›†è­¦å‘Šä¿¡æ¯
            warnings = []
            failed_images = []
            
            for vlm_data in vlm_responses:
                if not vlm_data["response"]["success"]:
                    failed_images.append(vlm_data["image_name"])
            
            if failed_images:
                warnings.append(f"ä»¥ä¸‹å›¾ç‰‡åˆ†æå¤±è´¥: {', '.join(failed_images)}")
            
            # åˆ›å»ºæœ€ç»ˆç»“æœ
            result = ExplainerResult(
                status=ExplanationStatus.SUCCESS if analysis_results["successful_count"] > 0 else ExplanationStatus.ERROR,
                explanations=analysis_results["explanations"],
                summary=analysis_results["summary"],
                insights=analysis_results["insights"],
                images_analyzed=state["processed_images"],
                processing_time=processing_time,
                vlm_calls=vlm_calls,
                error=None if analysis_results["successful_count"] > 0 else "æ‰€æœ‰å›¾ç‰‡åˆ†æå‡å¤±è´¥",
                warnings=warnings
            )
            
            state["explanation_result"] = result
            return state
            
        except Exception as e:
            state["error_info"] = {
                "type": "result_creation_error",
                "message": f"åˆ›å»ºæœ€ç»ˆç»“æœå¤±è´¥: {str(e)}"
            }
            return state
    
    def _save_dialogue(self, state: ExplainerState) -> ExplainerState:
        """ä¿å­˜å¯¹è¯è®°å½•"""
        try:
            if not state.get("explanation_result"):
                return state
            
            session_id = state["session_id"]
            coder_output = state["request"]["coder_output"]
            explainer_result = state["explanation_result"]
            user_request = coder_output.get("user_input", "")
            
            # ä¿å­˜å¯¹è¯è®°å½•
            dialogue_file = self.dialogue_manager.save_dialogue_record(
                session_id, user_request, coder_output, explainer_result
            )
            
            # ç”Ÿæˆè§£é‡ŠæŠ¥å‘Š
            report_file = self.dialogue_manager.generate_explanation_report(
                session_id, explainer_result, coder_output
            )
            
            state["output_file_path"] = report_file
            
            print(f"ğŸ’¾ å¯¹è¯è®°å½•å·²ä¿å­˜: {dialogue_file}")
            print(f"ğŸ“„ è§£é‡ŠæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            
            # æ ‡è®°å®Œæˆ
            state["current_step"] = "completed"
            
            return state
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¯¹è¯è®°å½•å¤±è´¥: {str(e)}")
            return state
    
    def get_final_result(self, state: ExplainerState) -> Dict[str, Any]:
        """è·å–æœ€ç»ˆç»“æœ"""
        # ä»¥ explanation_result æ˜¯å¦å­˜åœ¨ä½œä¸ºæˆåŠŸåˆ¤å®šï¼Œæ›´ç¨³å¥
        if state.get("explanation_result"):
            result = state["explanation_result"]
            return {
                "success": True,
                "session_id": state.get("session_id"),
                "explanations": result.get("explanations", []),
                "summary": result.get("summary", ""),
                "insights": result.get("insights", []),
                "images_count": len(result.get("images_analyzed", [])),
                "processing_time": result.get("processing_time", 0.0),
                "vlm_calls": result.get("vlm_calls", 0),
                "warnings": result.get("warnings", []),
                "output_file": state.get("output_file_path"),
                "dialogue_saved": bool(state.get("output_file_path"))
            }
        else:
            error_info = state.get("error_info") or {}
            return {
                "success": False,
                "session_id": state.get("session_id"),
                "error": error_info.get("message", "æœªçŸ¥é”™è¯¯"),
                "error_type": error_info.get("type", "unknown"),
                "step": state.get("current_step", "unknown"),
                "retry_count": state.get("retry_count", 0)
            }
    
    # è¾…åŠ©æ–¹æ³•
    def _create_image_info(self, image_path: str) -> ImageInfo:
        """åˆ›å»ºå›¾ç‰‡ä¿¡æ¯"""
        path = Path(image_path)
        return ImageInfo(
            file_path=str(path),
            file_name=path.name,
            file_size=path.stat().st_size if path.exists() else 0,
            created_time=path.stat().st_mtime if path.exists() else 0,
            image_type=path.suffix.lower()
        )
    
    def _get_dataset_description(self, dataset_name: str) -> str:
        """è·å–æ•°æ®é›†æè¿°"""
        # å°è¯•ä»æ•°æ®é›†æè¿°æ–‡ä»¶ä¸­è¯»å–
        desc_dir = Path("dataset/full_description")
        if desc_dir.exists():
            for desc_file in desc_dir.glob("*.txt"):
                if dataset_name.lower() in desc_file.name.lower():
                    try:
                        return desc_file.read_text(encoding='utf-8')
                    except Exception:
                        pass
        return f"æ•°æ®é›†: {dataset_name}"
    
    def _summarize_code(self, code: str) -> str:
        """æ€»ç»“ä»£ç çš„å…³é”®æ“ä½œ"""
        if not code:
            return "æ— ä»£ç ä¿¡æ¯"
        
        lines = code.split('\n')
        key_operations = []
        
        for line in lines:
            line = line.strip()
            if any(keyword in line for keyword in [
                'plt.', 'sns.', 'plot', 'hist', 'scatter', 'savefig',
                'DataFrame', 'groupby', 'agg', 'merge'
            ]):
                key_operations.append(line)
        
        return "; ".join(key_operations[:5])  # åªå–å‰5ä¸ªå…³é”®æ“ä½œ
    
    def _extract_key_findings(self, explanation: str) -> List[str]:
        """ä»è§£é‡Šä¸­æå–å…³é”®å‘ç°"""
        findings = []
        lines = explanation.split('\n')
        
        in_findings_section = False
        for line in lines:
            line = line.strip()
            
            # æŸ¥æ‰¾å…³é”®å‘ç°ç›¸å…³çš„ç« èŠ‚
            if any(keyword in line.lower() for keyword in [
                'å…³é”®å‘ç°', 'key findings', 'ä¸»è¦å‘ç°', 'é‡è¦è§‚å¯Ÿ'
            ]):
                in_findings_section = True
                continue
            
            # å¦‚æœåœ¨å‘ç°ç« èŠ‚ä¸­ï¼Œæ”¶é›†åˆ—è¡¨é¡¹
            if in_findings_section:
                if line.startswith('-') or line.startswith('â€¢') or line.startswith('*'):
                    findings.append(line[1:].strip())
                elif line.startswith('#') or not line:
                    # é‡åˆ°æ–°ç« èŠ‚æˆ–ç©ºè¡Œï¼Œåœæ­¢æ”¶é›†
                    break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„å‘ç°ç« èŠ‚ï¼Œå°è¯•æå–å‰å‡ ä¸ªè¦ç‚¹
        if not findings:
            for line in lines:
                line = line.strip()
                if (line.startswith('-') or line.startswith('â€¢') or line.startswith('*')) and len(line) > 10:
                    findings.append(line[1:].strip())
                    if len(findings) >= 3:
                        break
        
        return findings[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®å‘ç°
    
    def _parse_insights(self, insights_text: str) -> List[str]:
        """è§£ææ´å¯Ÿæ–‡æœ¬ä¸ºåˆ—è¡¨"""
        insights = []
        lines = insights_text.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('-') or line.startswith('â€¢') or line.startswith('*'):
                insight = line[1:].strip()
                if insight and len(insight) > 5:
                    insights.append(insight)
        
        return insights
