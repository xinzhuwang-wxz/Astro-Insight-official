# Maxen Wong
# SPDX-License-Identifier: MIT

"""
Commandè¯­æ³•èŠ‚ç‚¹å®ç°
ä½¿ç”¨LangGraph 0.2+çš„Commandè¯­æ³•é‡æ„æ ¸å¿ƒèŠ‚ç‚¹
"""

from typing import Dict, Any, List, Optional, Union, Literal
import time
import logging
import json
from langchain_core.language_models import BaseChatModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.types import Command

from src.graph.types import AstroAgentState, ExecutionStatus
from src.llms.llm import get_llm_by_type
from src.prompts.template import get_prompt


def track_node_execution(node_name: str):
    """èŠ‚ç‚¹æ‰§è¡Œè·Ÿè¸ªè£…é¥°å™¨"""
    def decorator(func):
        def wrapper(state: AstroAgentState) -> Command[AstroAgentState]:
            # æ›´æ–°å½“å‰èŠ‚ç‚¹
            updated_state = state.copy()
            updated_state["current_node"] = node_name
            
            # æ·»åŠ åˆ°èŠ‚ç‚¹å†å²ï¼ˆå¦‚æœä¸åœ¨å†å²ä¸­ï¼‰
            node_history = updated_state.get("node_history", [])
            if not node_history or node_history[-1] != node_name:
                node_history.append(node_name)
                updated_state["node_history"] = node_history
            
            # è¾“å‡ºèŠ‚ç‚¹ä¿¡æ¯
            print(f"\nğŸ” å½“å‰èŠ‚ç‚¹: {node_name}")
            if len(node_history) > 1:
                print(f"ğŸ“‹ å†å²èŠ‚ç‚¹: {' â†’ '.join(node_history[:-1])}")
            else:
                print(f"ğŸ“‹ å†å²èŠ‚ç‚¹: (èµ·å§‹èŠ‚ç‚¹)")
            
            # æ‰§è¡ŒåŸå‡½æ•°
            result = func(updated_state)
            
            # å¦‚æœè¿”å›çš„æ˜¯Commandå¯¹è±¡ï¼Œæ›´æ–°å…¶çŠ¶æ€
            if isinstance(result, Command):
                # åˆå¹¶èŠ‚ç‚¹è·Ÿè¸ªä¿¡æ¯åˆ°Commandçš„updateä¸­
                if result.update:
                    result.update.update({
                        "current_node": node_name,
                        "node_history": node_history
                    })
                else:
                    result.update = {
                        "current_node": node_name,
                        "node_history": node_history
                    }
            
            return result
        return wrapper
    return decorator
# from src.tools.language_processor import language_processor  # æš‚æ—¶æœªä½¿ç”¨
# å­˜å‚¨åŠŸèƒ½å·²ç§»é™¤ - åˆ†ç±»èŠ‚ç‚¹ä¸å†éœ€è¦æ•°æ®åº“å­˜å‚¨


def _extract_celestial_name_simple(user_input: str) -> str:
    """ä»ç”¨æˆ·è¾“å…¥ä¸­æå–å¤©ä½“åç§° - ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼ˆå‚è€ƒcomplete_simple_system.pyï¼‰"""
    import re
    
    # ç§»é™¤å¸¸è§çš„åˆ†ç±»å…³é”®è¯
    clean_input = user_input
    keywords_to_remove = [
        "åˆ†ç±»", "classify", "è¿™ä¸ªå¤©ä½“", "è¿™ä¸ª", "å¤©ä½“", "celestial", "object",
        "æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆç±»å‹", "ä»€ä¹ˆ", "ç±»å‹", "type", "åˆ†æ", "analyze"
    ]
    
    for keyword in keywords_to_remove:
        clean_input = clean_input.replace(keyword, "")
    
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·
    clean_input = re.sub(r'[ï¼š:ï¼Œ,ã€‚.ï¼!ï¼Ÿ?]', '', clean_input)
    
    # æå–å¯èƒ½çš„å¤©ä½“åç§°
    # åŒ¹é…å¸¸è§çš„å¤©ä½“å‘½åæ¨¡å¼
    patterns = [
        r'M\d+',  # æ¢…è¥¿è€¶å¤©ä½“
        r'NGC\s*\d+',  # NGCå¤©ä½“
        r'IC\s*\d+',  # ICå¤©ä½“
        r'HD\s*\d+',  # HDæ˜Ÿè¡¨
        r'[A-Z][a-z]+\s*\d+',  # æ˜Ÿåº§+æ•°å­—
        r'[A-Z][a-z]+',  # æ˜Ÿåº§å
        r'[A-Z]\d+',  # å•å­—æ¯+æ•°å­—
    ]
    
    for pattern in patterns:
        match = re.search(pattern, clean_input, re.IGNORECASE)
        if match:
            return match.group().strip()
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ¨¡å¼ï¼Œè¿”å›æ¸…ç†åçš„è¾“å…¥
    return clean_input.strip() if clean_input.strip() else ""


def extract_celestial_info_from_query(user_input: str, user_requirements: str = None) -> dict:
    """ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–å¤©ä½“ä¿¡æ¯ - ä½¿ç”¨ç®€å•æœ‰æ•ˆçš„æå–é€»è¾‘"""
    try:
        # ä½¿ç”¨ç®€å•è§„åˆ™æå–å¤©ä½“åç§°ï¼ˆå‚è€ƒcomplete_simple_system.pyï¼‰
        celestial_name = _extract_celestial_name_simple(user_input)
        
        if not celestial_name:
            celestial_info = {
                "object_name": "æœªçŸ¥å¤©ä½“",
                "coordinates": {"ra": None, "dec": None},
                "object_type": "æœªçŸ¥",
                "magnitude": None,
                "description": user_input
            }
        else:
            # æ„å»ºå¤©ä½“ä¿¡æ¯
            celestial_info = {
                "object_name": celestial_name,
                "coordinates": {"ra": None, "dec": None},
                "object_type": "æœªçŸ¥",
                "magnitude": None,
                "description": user_input
            }
        
        return celestial_info
    except Exception as e:
        logging.warning(f"æå–å¤©ä½“ä¿¡æ¯å¤±è´¥: {e}")
        return {
            "object_name": "æœªçŸ¥å¤©ä½“",
            "coordinates": {"ra": None, "dec": None},
            "object_type": "æœªçŸ¥",
            "magnitude": None,
            "description": user_input
        }


def _classify_celestial_object_with_llm(user_input: str, celestial_info: dict, llm) -> dict:
    """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å¤©ä½“åˆ†ç±»ï¼ˆå‚è€ƒcomplete_simple_system.pyï¼‰"""
    try:
        object_name = celestial_info.get("object_name", "æœªçŸ¥å¤©ä½“")
        
        # æ„å»ºåˆ†ç±»æç¤ºè¯
        classification_prompt = f"""è¯·å¯¹ä»¥ä¸‹å¤©ä½“è¿›è¡Œä¸“ä¸šçš„å¤©ä½“åˆ†ç±»ã€‚

å¤©ä½“åç§°: {object_name}
ç”¨æˆ·æŸ¥è¯¢: {user_input}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›åˆ†ç±»ç»“æœï¼ˆJSONæ ¼å¼ï¼‰ï¼š
{{
    "object_name": "å¤©ä½“åç§°",
    "primary_category": "ä¸»è¦ç±»åˆ«",
    "subcategory": "å­ç±»åˆ«", 
    "detailed_classification": "è¯¦ç»†åˆ†ç±»",
    "confidence_level": "ç½®ä¿¡åº¦",
    "scientific_name": "ç§‘å­¦åç§°",
    "object_type": "å¤©ä½“ç±»å‹",
    "description": "ç®€è¦æè¿°"
}}

ä¸»è¦ç±»åˆ«é€‰é¡¹ï¼š
- æ’æ˜Ÿ (Star)
- è¡Œæ˜Ÿ (Planet) 
- æ˜Ÿç³» (Galaxy)
- æ˜Ÿäº‘ (Nebula)
- æ˜Ÿå›¢ (Cluster)
- å°è¡Œæ˜Ÿ (Asteroid)
- å½—æ˜Ÿ (Comet)
- åŒæ˜Ÿ (Binary Star)
- è¶…æ–°æ˜Ÿ (Supernova)
- æ·±ç©ºå¤©ä½“ (Deep Sky Object)

è¯·æ ¹æ®å¤©ä½“åç§°å’ŒæŸ¥è¯¢å†…å®¹è¿›è¡Œå‡†ç¡®åˆ†ç±»ï¼š"""

        # è°ƒç”¨LLM
        from langchain_core.messages import HumanMessage
        messages = [HumanMessage(content=classification_prompt)]
        response = llm.invoke(messages)
        
        # è§£æå“åº”
        response_content = response.content.strip()
        
        # å°è¯•è§£æJSON
        try:
            import json
            # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤markdownä»£ç å—æ ¼å¼
            if "```json" in response_content:
                response_content = response_content.split("```json")[1].split("```")[0]
            elif "```" in response_content:
                response_content = response_content.split("```")[1].split("```")[0]
            
            classification_data = json.loads(response_content)
            
            return {
                "classification_result": classification_data,
                "success": True,
                "method": "llm_classification"
            }
            
        except json.JSONDecodeError:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™åˆ†ç±»ä½œä¸ºåå¤‡
            return _classify_celestial_object_by_rules(user_input, celestial_info)
            
    except Exception as e:
        print(f"LLMåˆ†ç±»å¤±è´¥: {e}")
        # ä½¿ç”¨è§„åˆ™åˆ†ç±»ä½œä¸ºåå¤‡
        return _classify_celestial_object_by_rules(user_input, celestial_info)


def _analyze_data_for_visualization(data: dict) -> str:
    """åˆ†ææ•°æ®ç‰¹å¾ï¼Œä¸ºå¯è§†åŒ–æä¾›å»ºè®®"""
    if not data:
        return "æ•°æ®ä¸ºç©ºã€‚"
    
    analysis_parts = []
    
    # æ•°æ®å­—æ®µæ£€æŸ¥ï¼ˆå·²ç®€åŒ–ï¼Œä¸æ˜¾ç¤ºå»ºè®®ï¼‰
    if not analysis_parts:
        analysis_parts.append("æ•°æ®å­—æ®µå®Œæ•´")
    
    return "\n".join(analysis_parts)


def _classify_celestial_object_by_rules(user_input: str, celestial_info: dict) -> dict:
    """åŸºäºè§„åˆ™çš„å¤©ä½“åˆ†ç±»"""
    try:
        # ç®€å•çš„åŸºäºå…³é”®è¯çš„åˆ†ç±»é€»è¾‘
        user_input_lower = user_input.lower()
        object_name = celestial_info.get("object_name", "").lower()
        
        # åˆ†ç±»é€»è¾‘
        if any(keyword in user_input_lower or keyword in object_name for keyword in ["æ’æ˜Ÿ", "star", "å¤ªé˜³"]):
            primary_category = "æ’æ˜Ÿ"
            subcategory = "ä¸»åºæ˜Ÿ"
        elif any(keyword in user_input_lower or keyword in object_name for keyword in ["è¡Œæ˜Ÿ", "planet", "ç«æ˜Ÿ", "é‡‘æ˜Ÿ", "æœ¨æ˜Ÿ"]):
            primary_category = "è¡Œæ˜Ÿ"
            subcategory = "ç±»åœ°è¡Œæ˜Ÿ" if any(k in user_input_lower for k in ["ç«æ˜Ÿ", "é‡‘æ˜Ÿ", "åœ°çƒ"]) else "æ°”æ€å·¨è¡Œæ˜Ÿ"
        elif any(keyword in user_input_lower or keyword in object_name for keyword in ["æ˜Ÿç³»", "galaxy", "é“¶æ²³", "ä»™å¥³åº§", "ä»™å¥³åº§æ˜Ÿç³»", "m31", "andromeda"]):
            primary_category = "æ˜Ÿç³»"
            subcategory = "èºæ—‹æ˜Ÿç³»"
        elif any(keyword in user_input_lower or keyword in object_name for keyword in ["æ˜Ÿäº‘", "nebula"]):
            primary_category = "æ˜Ÿäº‘"
            subcategory = "å‘å°„æ˜Ÿäº‘"
        elif "m87" in object_name or "m87" in user_input_lower:
            primary_category = "æ˜Ÿç³»"
            subcategory = "æ¤­åœ†æ˜Ÿç³»"
        elif object_name.startswith("m") and object_name[1:].isdigit():
            # æ¢…è¥¿è€¶å¤©ä½“çš„ä¸€èˆ¬åˆ†ç±»
            primary_category = "æ·±ç©ºå¤©ä½“"
            subcategory = "æ¢…è¥¿è€¶å¤©ä½“"
        else:
            primary_category = "æœªåˆ†ç±»"
            subcategory = "éœ€è¦æ›´å¤šä¿¡æ¯"
        
        return {
            "classification_result": {
                "object_name": celestial_info.get("object_name", "æœªçŸ¥å¤©ä½“"),
                "primary_category": primary_category,
                "subcategory": subcategory,
                "detailed_classification": f"{primary_category} - {subcategory}",
                "confidence_level": "ä¸­ç­‰",
                "key_features": ["åŸºäºå…³é”®è¯åˆ†æ"],
                "coordinates": celestial_info.get("coordinates", {"ra": "æœªçŸ¥", "dec": "æœªçŸ¥"}),
                "additional_info": {
                    "magnitude": celestial_info.get("magnitude", "æœªçŸ¥"),
                    "distance": "æœªçŸ¥",
                    "spectral_type": "æœªçŸ¥",
                },
            },
            "explanation": f"åŸºäºå…³é”®è¯åˆ†æï¼Œè¯¥å¤©ä½“è¢«åˆ†ç±»ä¸º{primary_category}ã€‚",
            "suggestions": ["æä¾›æ›´å¤šè§‚æµ‹æ•°æ®ä»¥è·å¾—æ›´å‡†ç¡®çš„åˆ†ç±»"],
        }
    except Exception as e:
        logging.warning(f"åŸºäºè§„åˆ™çš„åˆ†ç±»å¤±è´¥: {e}")
        return {
            "classification_result": {
                "object_name": "æœªçŸ¥å¤©ä½“",
                "primary_category": "æœªåˆ†ç±»",
                "subcategory": "åˆ†ç±»å¤±è´¥",
                "detailed_classification": "æ— æ³•åˆ†ç±»",
                "confidence_level": "ä½",
                "key_features": ["åˆ†ç±»å¤±è´¥"],
                "coordinates": {"ra": "æœªçŸ¥", "dec": "æœªçŸ¥"},
                "additional_info": {
                    "magnitude": "æœªçŸ¥",
                    "distance": "æœªçŸ¥",
                    "spectral_type": "æœªçŸ¥",
                },
            },
            "explanation": "åˆ†ç±»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ã€‚",
            "suggestions": ["è¯·é‡æ–°å°è¯•æˆ–æä¾›æ›´å¤šä¿¡æ¯"],
        }


# è®¾ç½®logger
logger = logging.getLogger(__name__)


# LLMæœåŠ¡åˆå§‹åŒ– - ä½¿ç”¨è±†åŒ…æ¨¡å‹
try:
    llm: BaseChatModel = get_llm_by_type("basic")
except Exception as e:
    print(f"Warning: Failed to initialize LLM: {e}")
    llm = None


@track_node_execution("identity_check")
def identity_check_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """
    èº«ä»½è¯†åˆ«èŠ‚ç‚¹ - Commandè¯­æ³•å®ç°
    åˆ¤æ–­ç”¨æˆ·ç±»å‹ï¼ˆamateur/professionalï¼‰å¹¶ç›´æ¥è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    """
    try:
        user_input = state["user_input"]  # åœ¨ä¸‹æ–¹promptä¸­ï¼Œç”¨æˆ·è¾“å…¥ä¼šè¢«Pythonè§£é‡Šå™¨ç«‹å³æ›¿æ¢ä¸º user_input å˜é‡çš„å®é™…å€¼
        
        # è¾“å…¥éªŒè¯
        if user_input is None or not isinstance(user_input, str):
            raise ValueError("Invalid user_input: must be a non-empty string")

        # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œèº«ä»½è¯†åˆ« - å®Œå…¨ä¾èµ–LLMåˆ¤æ–­
        if llm:
            identity_prompt = f"""è¯·ä»”ç»†åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­ç”¨æˆ·æ˜¯å¤©æ–‡çˆ±å¥½è€…è¿˜æ˜¯ä¸“ä¸šç ”ç©¶äººå‘˜ã€‚

ç”¨æˆ·è¾“å…¥: {user_input}

åˆ¤æ–­æ ‡å‡†ï¼š
- amateurï¼ˆçˆ±å¥½è€…ï¼‰ï¼šæ˜¯å¦è¡¨æ˜amateur(çˆ±å¥½è€…) è¯¢é—®åŸºç¡€å¤©æ–‡çŸ¥è¯†ã€æ¦‚å¿µè§£é‡Šã€ç§‘æ™®é—®é¢˜ã€å­¦ä¹ æ€§é—®é¢˜
  ä¾‹å¦‚ï¼š"ä»€ä¹ˆæ˜¯é»‘æ´å‘€ï¼Ÿ"ã€"æ’æ˜Ÿæ˜¯å¦‚ä½•å½¢æˆçš„å‘€ï¼Ÿ"ã€"é“¶æ²³ç³»æœ‰å¤šå¤§å‘€ï¼Ÿ"ã€"è¿™é¢—æ˜Ÿå¥½äº®å‘€"ã€"æœ‰è¶£çš„å¤©æ–‡ç°è±¡"
  
- professionalï¼ˆä¸“ä¸šç”¨æˆ·ï¼‰ï¼šæ˜¯å¦è¡¨æ˜professional(ä¸“ä¸šç”¨æˆ·)ï¼Œéœ€è¦ä¸“ä¸šåˆ†æã€æ•°æ®å¤„ç†ã€å¤©ä½“åˆ†ç±»ã€æ•°æ®æ£€ç´¢ã€å›¾è¡¨ç»˜åˆ¶ç­‰
  ä¾‹å¦‚ï¼š"M87å±äºä»€ä¹ˆç±»å‹ï¼Ÿ"ã€"åˆ†ç±»è¿™ä¸ªå¤©ä½“ï¼šM87"ã€"è·å–SDSSæ˜Ÿç³»æ•°æ®"ã€"ç»˜åˆ¶å¤©ä½“ä½ç½®å›¾"ã€"åˆ†æM87çš„å°„ç”µæ˜Ÿç³»ç‰¹å¾"ã€"M31çš„å‚è€ƒæ–‡çŒ®"ã€"M31çš„ç‰¹å¾"ã€"M31çš„æ€§è´¨"ã€"M31ç›¸å…³æ–‡çŒ®"ã€"ç¦»M31æœ€è¿‘çš„æ˜Ÿç³»æœ‰å“ªäº›"ã€"æä¾›åæ ‡åˆ¤æ–­æ˜Ÿç³»"

å…³é”®åŒºåˆ«ï¼š
- ä¼˜å…ˆçº§æœ€é«˜çš„æ˜¯èº«ä»½è¯†åˆ«ï¼Œå¦‚æœæ˜ç¡®çˆ±å¥½è€…ï¼ˆamateurï¼‰ï¼ŒæŒ‰ç…§amateurï¼ˆçˆ±å¥½è€…ï¼‰å¤„ç†ã€‚ é—®"æœ‰å¤šå¤§"ã€"è¿™é¢—æ˜Ÿå¥½äº®"ã€"æœ‰è¶£çš„å¤©æ–‡ç°è±¡" â†’ amateurï¼ˆç§‘æ™®é—®é¢˜ï¼‰
- ä¼˜å…ˆçº§æœ€é«˜çš„æ˜¯èº«ä»½è¯†åˆ«ï¼Œå¦‚æœæ˜ç¡®ä¸“ä¸šäººå£« (professional)ï¼ŒæŒ‰ç…§professionalï¼ˆä¸“ä¸šç”¨æˆ·ï¼‰å¤„ç†ã€‚é—®"å±äºä»€ä¹ˆç±»å‹"ã€"åˆ†ç±»"ã€"åˆ†æç‰¹å¾" â†’ professionalï¼ˆä¸“ä¸šåˆ†ç±»/åˆ†æï¼‰

è¯·ä»”ç»†åˆ†æç”¨æˆ·çš„è¯­è¨€é£æ ¼ã€é—®é¢˜æ·±åº¦å’Œä¸“ä¸šéœ€æ±‚ï¼Œç„¶ååªè¿”å›ï¼šamateur æˆ– professional
"""
            
            from langchain_core.messages import HumanMessage
            messages = [HumanMessage(content=identity_prompt)]
            response = llm.invoke(messages)  # æŒ‰promptè¦æ±‚ï¼Œåªè¿”å›amateur æˆ– professional
            user_type = response.content.strip().lower()
                
            # éªŒè¯å“åº”
            if user_type not in ["amateur", "professional"]:
                # å¦‚æœLLMè¿”å›çš„ä¸æ˜¯é¢„æœŸæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
                if "professional" in user_type or "ä¸“ä¸š" in user_type:
                    user_type = "professional"
                elif "amateur" in user_type or "çˆ±å¥½è€…" in user_type or "ä¸šä½™" in user_type:
                    user_type = "amateur"
                else:
                    user_type = "amateur"  # é»˜è®¤ä¸ºçˆ±å¥½è€…
        else:
            # å¦‚æœLLMä¸å¯ç”¨ï¼ŒæŠ¥é”™è€Œä¸æ˜¯ä½¿ç”¨å…³é”®è¯åˆ¤æ–­
            raise Exception("LLMæœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œèº«ä»½è¯†åˆ«")

        # æ›´æ–°çŠ¶æ€ - åªæ›´æ–°å¿…è¦çš„å­—æ®µï¼Œé¿å…å­—æ®µå†²çª
        updated_state = {
            "user_type": user_type,
            "current_step": "identity_checked",
            "identity_completed": True
        }

        # ä½¿ç”¨Commandè¯­æ³•ç›´æ¥è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        if user_type == "amateur":
            # ä¸šä½™ç”¨æˆ·éœ€è¦å…ˆè¿›è¡ŒQAé—®ç­”
            return Command(
                update=updated_state,
                goto="qa_agent"
            )
        elif user_type == "professional":
            # ä¸“ä¸šç”¨æˆ·ç›´æ¥è¿›å…¥ä»»åŠ¡é€‰æ‹©
            return Command(
                update=updated_state,
                goto="task_selector"
            )
        else:
            # å¼‚å¸¸æƒ…å†µï¼Œé»˜è®¤ä¸ºä¸šä½™ç”¨æˆ·ï¼Œè¿›å…¥QAé—®ç­”
            updated_state["user_type"] = "amateur"
            return Command(
                update=updated_state,
                goto="qa_agent"
            )

    except Exception as e:
        # é”™è¯¯å¤„ç† - åªæ›´æ–°å¿…è¦çš„å­—æ®µ
        error_state = {
            "error_info": {
                "node": "identity_check_command_node",
                "error": str(e),
                "timestamp": time.time(),
            }
        }
        
        return Command(
            update=error_state,
            goto="error_recovery"
        )


# å­˜å‚¨åŠŸèƒ½å·²ç§»é™¤ - åˆ†ç±»èŠ‚ç‚¹ä¸å†éœ€è¦æ•°æ®åº“å­˜å‚¨


# real_time_retrieval_command_nodeå·²åˆ é™¤ - åœ¨builder.pyä¸­æœªä½¿ç”¨


# æ•°æ®åº“å­˜å‚¨åŠŸèƒ½å·²ç§»é™¤ - åˆ†ç±»èŠ‚ç‚¹ä¸å†éœ€è¦æ•°æ®å­˜å‚¨


# å…¼å®¹ç‰ˆæœ¬çš„_nodeå‡½æ•°å·²åˆ é™¤ - åœ¨builder.pyä¸­æœªä½¿ç”¨


@track_node_execution("qa_agent")
def qa_agent_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """
    QAé—®ç­”èŠ‚ç‚¹ - ç®€åŒ–ç‰ˆæœ¬ï¼Œé›†æˆTavilyæœç´¢ï¼Œç›´æ¥ç»“æŸ
    å¤„ç†çˆ±å¥½è€…çš„å¤©æ–‡é—®ç­”ï¼Œä¸å†æä¾›ä¸“ä¸šæ¨¡å¼é€‰æ‹©
    """
    try:
        user_input = state["user_input"]
        user_type = state.get("user_type", "amateur")

        # é›†æˆTavilyæœç´¢è·å–æœ€æ–°ä¿¡æ¯
        search_context = ""
        search_sources = []
        tavily_success = False
        try:
            from src.tools.tavily_search.tavily_search_api_wrapper import tavily_search
            search_query = f"å¤©æ–‡ {user_input}"
            # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„max_resultsï¼Œä¸ä¼ å‚æ•°è®©å‡½æ•°è‡ªåŠ¨ä½¿ç”¨é…ç½®
            search_results = tavily_search(search_query)
            if search_results:
                # å°†æœç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™LLMï¼Œè®©LLMæ™ºèƒ½æ•´åˆ
                search_context = "\n\n[æœ€æ–°ç½‘ç»œä¿¡æ¯å‚è€ƒ] "
                for i, result in enumerate(search_results[:2], 1):
                    title = result.get('title', 'æ— æ ‡é¢˜')
                    content = result.get('content', 'æ— å†…å®¹')[:100]
                    url = result.get('url', '')
                    search_context += f"{title}: {content}... "
                    
                    # æ”¶é›†æ¥æºä¿¡æ¯ç”¨äºæœ€åçš„å‚è€ƒåˆ—è¡¨ï¼ˆä¿æŒåŸå§‹è¯­è¨€ï¼‰
                    if url:
                        domain = result.get('domain', 'unknown')
                        # ä¿æŒåŸå§‹æ ‡é¢˜ï¼Œä¸è¿›è¡Œç¿»è¯‘
                        search_sources.append(f"{title} ({domain})")
                
                search_context += "è¯·å°†è¿™äº›ä¿¡æ¯è‡ªç„¶åœ°æ•´åˆåˆ°å›ç­”ä¸­ï¼Œä¸è¦ç›´æ¥å¼•ç”¨ã€‚"
                tavily_success = True
        except Exception as e:
            print(f"Tavilyæœç´¢å¤±è´¥: {e}")
            search_context = ""

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤©ä½“åˆ†ç±»é—®é¢˜
        is_classification_question = (
            "åˆ†ç±»" in user_input or 
            "ç±»å‹" in user_input or 
            "å±äº" in user_input or
            # "æ˜¯ä»€ä¹ˆ" in user_input or  # â€œæ˜¯ä»€ä¹ˆâ€ é€‚åˆæ£€ç´¢ä»»åŠ¡
            state.get("current_step") == "simbad_query_failed"  # å¦‚æœSIMBADæŸ¥è¯¢å¤±è´¥ï¼Œè·³è½¬åˆ°QAä»£ç†å¤„ç†
        )
        
        # ä½¿ç”¨promptæ¨¡æ¿è·å–QAæç¤ºè¯
        try:
            if is_classification_question:
                # ä½¿ç”¨ä¸“é—¨çš„å¤©ä½“åˆ†ç±»prompt
                qa_prompt_content = f"""ä½œä¸ºä¸“ä¸šå¤©æ–‡å­¦å®¶ï¼Œè¯·å›ç­”ä»¥ä¸‹å¤©ä½“åˆ†ç±»é—®é¢˜ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{user_input}
ç”¨æˆ·ç±»å‹ï¼š{user_type}

è¯·æä¾›ï¼š
1. å¤©ä½“çš„å‡†ç¡®åˆ†ç±»ï¼ˆä¸»åˆ†ç±»ã€å­åˆ†ç±»ã€è¯¦ç»†åˆ†ç±»ï¼‰
2. è¯¥å¤©ä½“çš„åŸºæœ¬ç‰¹å¾å’Œæ€§è´¨
3. åœ¨å¤©æ–‡å­¦ä¸­çš„é‡è¦æ€§
4. ç›¸å…³çš„è§‚æµ‹ç‰¹å¾

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ï¼Œé€‚åˆ{user_type}ç”¨æˆ·çš„ç†è§£æ°´å¹³ã€‚"""
            else:
                qa_prompt_content = get_prompt(
                    "qa_agent", user_input=user_input, user_type=user_type
                )  # å¦‚æœç”¨æˆ·è¾“å…¥ä¸æ˜¯åˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨QAé—®ç­”æ¨¡æ¿
            qa_prompt = ChatPromptTemplate.from_template(qa_prompt_content)
        except Exception:
            qa_prompt = None

        # ç”Ÿæˆå›ç­”
        llm = get_llm_by_type("basic")
        if llm is None or qa_prompt is None:
            # ä¸´æ—¶å¤„ç†ï¼šå¦‚æœLLMæœªåˆå§‹åŒ–ï¼Œæä¾›é»˜è®¤å›ç­”
            response_content = f"æ„Ÿè°¢æ‚¨çš„å¤©æ–‡é—®é¢˜ï¼š{user_input}ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„å¤©æ–‡è¯é¢˜ï¼ç”±äºå½“å‰LLMæœåŠ¡æœªé…ç½®ï¼Œè¯·ç¨åå†è¯•ã€‚"
        else:
            # å°†æœç´¢ä¸Šä¸‹æ–‡æ·»åŠ åˆ°ç”¨æˆ·è¾“å…¥ä¸­
            enhanced_input = user_input + search_context
            chain = qa_prompt | llm
            response = chain.invoke({"user_input": enhanced_input, "user_type": user_type})
            # ç¡®ä¿ response_content æ˜¯å­—ç¬¦ä¸²
            if hasattr(response, 'content'):
                response_content = str(response.content)
            else:
                response_content = str(response)

        # ç›´æ¥ä½¿ç”¨LLMæ•´åˆåçš„å›ç­”ï¼Œä¸å†æ·»åŠ åŸå§‹æœç´¢ç»“æœ
        final_response = response_content
        
        # å¦‚æœ Tavily æœç´¢æˆåŠŸå¹¶è¿”å›äº†ç»“æœï¼Œæ·»åŠ å‚è€ƒæ¥æº
        if tavily_success and search_sources:
            final_response += "\n\nğŸ“š å‚è€ƒæ¥æºï¼š\n"
            for i, source in enumerate(search_sources[:3], 1):
                final_response += f"{i}. {source}\n"

        # æ›´æ–°çŠ¶æ€
        updated_state = state.copy()
        updated_state["qa_response"] = final_response
        updated_state["final_answer"] = f"QAå›ç­”: {final_response}"
        updated_state["current_step"] = "qa_completed"
        updated_state["is_complete"] = True
        updated_state["task_type"] = "qa"

        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
        if "messages" not in updated_state:
            updated_state["messages"] = []
        updated_state["messages"].append({"role": "assistant", "content": final_response})  # ä½œç”¨æ˜¯è®°å½•å¯¹è¯å†å²

        # è®°å½•æ‰§è¡Œå†å²
        execution_history = updated_state.get("execution_history", [])
        execution_history.append({
            "node": "qa_agent_command_node",
            "action": "generate_qa_response_with_search",
            "input": user_input,
            "output": final_response,
            "timestamp": time.time(),
        })
        
        updated_state["execution_history"] = execution_history

        # ç›´æ¥ç»“æŸï¼Œä¸å†è¯¢é—®æ˜¯å¦è¿›å…¥ä¸“ä¸šæ¨¡å¼
        return Command(
            update=updated_state,
            goto="__end__"
        )

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_message = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼š{str(e)}ã€‚è¯·ç¨åå†è¯•ã€‚"
        error_state = state.copy()
        error_state["final_answer"] = error_message
        error_state["qa_response"] = f"QAé”™è¯¯: {error_message}"
        error_state["error_info"] = {
            "node": "qa_agent_command_node",
            "error": str(e),
            "timestamp": time.time(),
        }
        error_state["retry_count"] = error_state.get("retry_count", 0) + 1
        
        return Command(
            update=error_state,
            goto="error_recovery"
        )


@track_node_execution("classification_config")
def classification_config_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """
    å¤©ä½“åˆ†ç±»é…ç½®èŠ‚ç‚¹ - Commandè¯­æ³•å®ç°
    æ ¹æ®ç”¨æˆ·è¾“å…¥çš„å¤©ä½“ä¿¡æ¯è¿›è¡Œå¤©ä½“åˆ†ç±»ï¼Œå¹¶å®Œæˆå®æ—¶æ•°æ®æ£€ç´¢å’Œæ•°æ®åº“å­˜å‚¨
    """
    try:
        user_input = state["user_input"]
        user_requirements = state.get("user_requirements", user_input)
        
        # ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–å¤©ä½“ä¿¡æ¯
        celestial_info = extract_celestial_info_from_query(
            user_input, user_requirements
        )

        # ä½¿ç”¨promptæ¨¡æ¿è·å–é…ç½®æç¤ºè¯
        try:
            config_prompt_content = get_prompt(
                "classification_config",
                user_query=user_input,
                celestial_info=str(celestial_info),
                task_type="classification",
            )
        except Exception:
            config_prompt_content = None

        # è°ƒç”¨LLMè¿›è¡Œå¤©ä½“åˆ†ç±»
        llm = get_llm_by_type("basic")
        if llm is None:
            # ä½¿ç”¨å¢å¼ºçš„åŸºäºè§„åˆ™çš„åˆ†ç±»é€»è¾‘
            classification_result = _classify_celestial_object_by_rules(
                user_input, celestial_info
            )
        else:
            try:
                # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å¤©ä½“åˆ†ç±»ï¼ˆå‚è€ƒcomplete_simple_system.pyï¼‰
                classification_result = _classify_celestial_object_with_llm(
                    user_input, celestial_info, llm
                    )
            except Exception:
                # LLMè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†ç±»é€»è¾‘ä½œä¸ºfallback
                classification_result = _classify_celestial_object_by_rules(
                    user_input, celestial_info
                )

        # === é›†æˆå®æ—¶æ•°æ®æ£€ç´¢åŠŸèƒ½ ===
        # ä»åˆ†ç±»ç»“æœä¸­è·å–å¤©ä½“ä¿¡æ¯
        celestial_info_result = classification_result.get("classification_result", {})
        object_name = celestial_info_result.get("object_name", "Unknown")
        object_type = celestial_info_result.get("primary_category", "Unknown")
        coordinates = celestial_info_result.get("coordinates", {})
        
        # å°è¯•ä»SIMBADè·å–å®æ—¶æ•°æ®
        from src.code_generation.templates import query_simbad_by_name
        
        simbad_result = query_simbad_by_name(object_name)
        
        # å¦‚æœSIMBADæŸ¥è¯¢å¤±è´¥ï¼Œè·³è½¬åˆ°QAä»£ç†å¤„ç†
        if not simbad_result.get('found', False):
            # æ›´æ–°çŠ¶æ€ï¼Œè·³è½¬åˆ°QAä»£ç†
            updated_state = state.copy()
            updated_state["current_step"] = "simbad_query_failed"
            updated_state["simbad_failed_object"] = object_name
            updated_state["user_input"] = f"è¯·æ‰¾åˆ°{object_name}æ‰€å±çš„åˆ†ç±»ï¼Œå¹¶åšç®€å•ä»‹ç»"
            
            # è®°å½•æ‰§è¡Œå†å²
            execution_history = updated_state.get("execution_history", [])
            execution_history.append({
                "node": "classification_config_command_node",
                "action": "simbad_query_failed_redirect_to_qa",
                "input": user_input,
                "output": f"SIMBADæŸ¥è¯¢å¤±è´¥ï¼Œè·³è½¬åˆ°QAä»£ç†å¤„ç†{object_name}åˆ†ç±»",
                "timestamp": time.time(),
            })
            updated_state["execution_history"] = execution_history
            
            return Command(
                update=updated_state,
                goto="qa_agent"
            )
        
        if simbad_result.get('found', False):
            # ä»SIMBADè·å–åˆ°æ•°æ®
            ra_val = simbad_result.get('coordinates', {}).get('ra', None)
            dec_val = simbad_result.get('coordinates', {}).get('dec', None)
            
            # ç¡®ä¿åæ ‡å€¼æ˜¯æ•°å­—ç±»å‹
            try:
                ra_val = float(ra_val) if ra_val is not None else None
            except (ValueError, TypeError):
                ra_val = None
            try:
                dec_val = float(dec_val) if dec_val is not None else None
            except (ValueError, TypeError):
                dec_val = None
                
            real_coordinates = {"ra": ra_val, "dec": dec_val}
            real_magnitude = simbad_result.get('magnitude', None)
            object_name = simbad_result.get('object_name', object_name)
        else:
            # å¦‚æœSIMBADæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ç°æœ‰åæ ‡æˆ–æ ‡è®°ä¸ºæœªæ‰¾åˆ°
            real_coordinates = coordinates if coordinates.get("ra") and coordinates.get("dec") else {"ra": None, "dec": None}
            real_magnitude = None
        
        # æ„å»ºæ£€ç´¢ç»“æœï¼ˆåªæ˜¾ç¤ºçœŸå®æŸ¥è¯¢çš„æ•°æ®æºå’Œå­—æ®µï¼‰
        data_sources = ["SIMBAD"] if simbad_result.get('found', False) else []
        retrieval_result = {
            "status": "success" if simbad_result.get('found', False) else "no_data",
            "data_sources_queried": data_sources,
            "total_records": 1 if simbad_result.get('found', False) else 0,
            "query_timestamp": time.time()
        }
        
        # åªæ·»åŠ SIMBADå®é™…è¿”å›çš„å­—æ®µ
        if simbad_result.get('found', False):
            retrieval_result["coordinates"] = real_coordinates
            retrieval_result["object_type"] = simbad_result.get('object_type', 'Unknown')
            if real_magnitude is not None:
                retrieval_result["magnitude"] = real_magnitude
        
        # åˆ†ç±»ä»»åŠ¡ä¸éœ€è¦å­˜å‚¨æ•°æ®ï¼Œç›´æ¥è¿”å›åˆ†æç»“æœ

        # æ›´æ–°çŠ¶æ€
        updated_state = state.copy()
        updated_state["classification_result"] = classification_result
        updated_state["retrieval_result"] = retrieval_result
        updated_state["classification_config"] = {
            "configured": True,
            "celestial_info": celestial_info,
            "classification_method": "llm_analysis" if llm else "rule_based",
            "timestamp": time.time(),
        }
        updated_state["current_step"] = "classification_and_storage_completed"
        updated_state["is_complete"] = True

        # è®°å½•æ‰§è¡Œå†å²
        execution_history = updated_state.get("execution_history", [])
        execution_history.append({
            "node": "classification_config_command_node",
            "action": "celestial_classification_with_storage",
            "input": user_input,
            "output": f"Classified {object_name} as {object_type}, retrieved and stored data",
            "timestamp": time.time(),
        })
        updated_state["execution_history"] = execution_history

        # åˆå§‹åŒ–å¯¹è¯å†å²
        if "conversation_history" not in updated_state:
            updated_state["conversation_history"] = []

        # æ·»åŠ åˆ†ç±»ç»“æœåˆ°å¯¹è¯å†å²
        updated_state["conversation_history"].append({
            "type": "system",
            "content": f"å¤©ä½“åˆ†æå®Œæˆï¼š{object_name} - {object_type}",
            "timestamp": time.time(),
        })
        
        # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        coord_display = f"RA={real_coordinates.get('ra', 'N/A')}, DEC={real_coordinates.get('dec', 'N/A')}"
        magnitude = real_magnitude if real_magnitude is not None else "N/A"
        
        # åˆ†ææ•°æ®ç‰¹å¾ï¼Œä¸ºå¯è§†åŒ–æä¾›å»ºè®®
        data_analysis = _analyze_data_for_visualization(retrieval_result)
        
        # æ„å»ºè¯¦ç»†çš„åˆ†ç±»ç»“æœæ˜¾ç¤º
        simbad_classification = ""
        if simbad_result.get('found', False):
            # è·å–åˆ†ç±»ä¿¡æ¯
            main_cat = simbad_result.get('main_category', '')
            sub_cat = simbad_result.get('sub_category', '')
            detailed = simbad_result.get('detailed_classification', '')
            simbad_type = simbad_result.get('object_type', 'N/A')
            
            # å¸¸è¯†æ€§éªŒè¯ï¼šM31åº”è¯¥æ˜¯æ—‹æ¶¡æ˜Ÿç³»ï¼Œä¸æ˜¯å°„ç”µæ˜Ÿç³»
            if object_name.upper() in ['M31', 'MESSIER 31', 'NGC 224', 'ä»™å¥³åº§æ˜Ÿç³»']:
                if 'å°„ç”µæ˜Ÿç³»' in sub_cat or 'å°„ç”µæ˜Ÿç³»' in detailed:
                    # ä¿®æ­£ä¸ºæ­£ç¡®çš„åˆ†ç±»
                    main_cat = 'æ˜Ÿç³»'
                    sub_cat = 'æ—‹æ¶¡æ˜Ÿç³»'
                    detailed = 'æ—‹æ¶¡æ˜Ÿç³» (Spiral Galaxy)'
                    simbad_type = 'S'  # æ—‹æ¶¡æ˜Ÿç³»çš„SIMBADä»£ç 
            
            # æ¸…ç†å’Œæ„å»ºå±‚æ¬¡ç»“æ„ - ç›´æ¥ä½¿ç”¨SIMBADåŸå§‹æ•°æ®ï¼Œä¸è¿›è¡Œç¡¬ç¼–ç æ˜ å°„
            hierarchy = []
            
            # ç›´æ¥ä½¿ç”¨SIMBADè¿”å›çš„åˆ†ç±»æ•°æ®ï¼Œä¿æŒåŸå§‹å‡†ç¡®æ€§
            if main_cat and main_cat not in ['Unknown', 'N/A', '']:
                hierarchy.append(main_cat)
            
            if sub_cat and sub_cat not in ['Unknown', 'N/A', ''] and sub_cat != main_cat:
                hierarchy.append(sub_cat)
            
            if detailed and detailed not in ['Unknown', 'N/A', ''] and detailed != sub_cat and detailed != main_cat:
                hierarchy.append(detailed)
            
            # å»é‡å¤„ç†ï¼šç§»é™¤é‡å¤çš„å±‚çº§
            unique_hierarchy = []
            for level in hierarchy:
                if level not in unique_hierarchy:
                    unique_hierarchy.append(level)
            hierarchy = unique_hierarchy
            
            # æ„å»ºç¼©è¿›å¼å±‚æ¬¡ç»“æ„
            hierarchy_tree = ""
            if hierarchy:
                for i, level in enumerate(hierarchy):
                    indent = "  " * i  # æ¯å±‚ç¼©è¿›2ä¸ªç©ºæ ¼
                    hierarchy_tree += f"{indent}â””â”€ {level}\n"
                hierarchy_tree = hierarchy_tree.rstrip()  # ç§»é™¤æœ€åçš„æ¢è¡Œç¬¦
            else:
                hierarchy_tree = "â””â”€ æœªçŸ¥ç±»å‹"
            
            # æ„å»ºSIMBADåˆ†ç±»è¯¦æƒ…
            simbad_classification = f"""
SIMBADåˆ†ç±»è¯¦æƒ…:
- SIMBADç±»å‹: {simbad_type}
- åˆ†ç±»å±‚æ¬¡:
{hierarchy_tree}
- å…³é”®ç‰¹å¾: {simbad_result.get('key_features', 'N/A')}
- ç½®ä¿¡åº¦: {simbad_result.get('confidence', 'N/A')}"""

        
        # ä½¿ç”¨ä¸­æ–‡åˆ†ç±»ç»“æœ
        main_cat = simbad_result.get('main_category', '') if simbad_result.get('found', False) else ''
        chinese_classification = main_cat if main_cat and main_cat not in ['Unknown', 'N/A', ''] else 'æœªçŸ¥ç±»å‹'
        
        final_answer = f"""å¤©ä½“åˆ†æå®Œæˆï¼
        
å¤©ä½“åç§°: {object_name}
åˆ†ç±»ç»“æœ: {chinese_classification}{simbad_classification}
åæ ‡: {coord_display}

{data_analysis}"""
        
        updated_state["final_answer"] = final_answer
        
        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°æ¶ˆæ¯åˆ—è¡¨
        if "messages" not in updated_state:
            updated_state["messages"] = []
        from langchain_core.messages import AIMessage
        updated_state["messages"].append(AIMessage(content=final_answer))

        # åˆ†ç±»ã€æ£€ç´¢å’Œå­˜å‚¨å®Œæˆåï¼Œç›´æ¥ç»“æŸæµç¨‹
        return Command(
            update=updated_state,
            goto="__end__"
        )

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_state = state.copy()
        error_state["error_info"] = {
            "node": "classification_config_command_node",
            "error": f"å¤©ä½“åˆ†æå¤±è´¥: {str(e)}",
            "timestamp": time.time(),
        }
        error_state["retry_count"] = error_state.get("retry_count", 0) + 1
        
        return Command(
            update=error_state,
            goto="error_recovery"
        )


# ç¬¬ä¸€ä¸ªdata_retrieval_command_nodeå®šä¹‰å·²åˆ é™¤ - ä½¿ç”¨ç¬¬äºŒä¸ªç‰ˆæœ¬ï¼ˆå¸¦è£…é¥°å™¨ï¼‰


# literature_review_command_nodeå·²åˆ é™¤ - åœ¨builder.pyä¸­æœªä½¿ç”¨


def error_recovery_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """é”™è¯¯æ¢å¤CommandèŠ‚ç‚¹ - å¤„ç†ç³»ç»Ÿé”™è¯¯å’Œå¼‚å¸¸æƒ…å†µï¼Œæœ€å¤§é‡è¯•3æ¬¡"""
    try:
        error_info = state.get("error_info")
        retry_count = state.get("retry_count", 0)
        last_error_node = state.get("last_error_node")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªèŠ‚ç‚¹çš„é‡å¤é”™è¯¯ï¼Œé¿å…æ— é™å¾ªç¯
        current_error_node = error_info.get("node") if error_info else None
        
        # æœ€å¤§é‡è¯•æ¬¡æ•°é™åˆ¶ä¸º3æ¬¡
        MAX_RETRY_COUNT = 3
        
        if retry_count >= MAX_RETRY_COUNT or (current_error_node == last_error_node and retry_count > 0):
            # è¶…è¿‡é‡è¯•æ¬¡æ•°æˆ–åŒä¸€èŠ‚ç‚¹é‡å¤é”™è¯¯ï¼Œæä¾›é™çº§æœåŠ¡å¹¶ç»“æŸæµç¨‹
            reason = "è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°" if retry_count >= MAX_RETRY_COUNT else "æ£€æµ‹åˆ°å¾ªç¯é”™è¯¯"
            
            fallback_response = f"""æŠ±æ­‰ï¼Œç³»ç»Ÿåœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ï¼ˆ{reason}ï¼‰ï¼Œç°åœ¨æä¾›åŸºæœ¬æœåŠ¡ã€‚
            
é”™è¯¯èŠ‚ç‚¹ï¼š{current_error_node or 'æœªçŸ¥'}
é”™è¯¯ä¿¡æ¯ï¼š{error_info.get('error', 'æœªçŸ¥é”™è¯¯') if error_info else 'ç³»ç»Ÿå¼‚å¸¸'}
é‡è¯•æ¬¡æ•°ï¼š{retry_count}

å»ºè®®ï¼š
1. è¯·ç®€åŒ–æ‚¨çš„é—®é¢˜é‡æ–°æé—®
2. æ£€æŸ¥è¾“å…¥æ ¼å¼æ˜¯å¦æ­£ç¡®
3. ç¨åå†è¯•

å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒã€‚"""

            # åªæ›´æ–°å¿…è¦çš„å­—æ®µï¼Œé¿å…å¤åˆ¶æ•´ä¸ªçŠ¶æ€
            updated_state = {
                "qa_response": fallback_response,
                "final_answer": f"é”™è¯¯å¤„ç†: {fallback_response}",
                "current_step": "error_handled",
                "is_complete": True
            }

            # å¤„ç†messages
            if "messages" in state:
                updated_state["messages"] = state["messages"].copy()
            else:
                updated_state["messages"] = []
            updated_state["messages"].append(
                {"role": "assistant", "content": fallback_response}
            )
            
            # ä¸æ›´æ–°execution_historyï¼Œé¿å…å­—æ®µå†²çª
            
            # ç»“æŸæµç¨‹ï¼Œä¸å†é‡è¯•
            return Command(
                update=updated_state,
                goto="__end__"
            )
        else:
            # åœ¨é‡è¯•é™åˆ¶å†…ï¼Œæ ¹æ®é”™è¯¯æ¥æºè¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ¢å¤
            updated_state = {
                "last_error_node": current_error_node,  # è®°å½•å½“å‰é”™è¯¯èŠ‚ç‚¹
                "error_recovery_completed": True
            }

            # ä¸æ›´æ–°execution_historyï¼Œé¿å…å­—æ®µå†²çª
            
            # æ ¹æ®é”™è¯¯æ¥æºå†³å®šæ¢å¤ç­–ç•¥
            error_node = error_info.get("node") if error_info else None
            
            # ç”±äºå·²ç»åˆå¹¶äº†èŠ‚ç‚¹ï¼Œç°åœ¨åªéœ€è¦å¤„ç†classification_config_command_nodeçš„é”™è¯¯
            if error_node == "classification_config_command_node":
                # åˆ†ç±»é”™è¯¯ï¼Œé‡è¯•åˆ†ç±»ï¼ˆç°åœ¨åŒ…å«äº†å®Œæ•´çš„åˆ†ææµç¨‹ï¼‰
                updated_state["current_step"] = "classification_retry"
                return Command(
                    update=updated_state,
                    goto="classification_config"
                )
            else:
                # å…¶ä»–é”™è¯¯æˆ–æœªçŸ¥é”™è¯¯ï¼Œæä¾›é™çº§æœåŠ¡å¹¶ç»“æŸ
                fallback_response = f"""æŠ±æ­‰ï¼Œç³»ç»Ÿé‡åˆ°äº†é—®é¢˜ï¼Œä½†æˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›åŸºæœ¬ä¿¡æ¯ã€‚
                
é”™è¯¯ä¿¡æ¯ï¼š{error_info.get('error', 'æœªçŸ¥é”™è¯¯') if error_info else 'ç³»ç»Ÿå¼‚å¸¸'}
é‡è¯•æ¬¡æ•°ï¼š{retry_count + 1}/{MAX_RETRY_COUNT}

å»ºè®®ï¼š
1. è¯·ç®€åŒ–æ‚¨çš„é—®é¢˜é‡æ–°æé—®
2. æ£€æŸ¥è¾“å…¥æ ¼å¼æ˜¯å¦æ­£ç¡®
3. ç¨åå†è¯•

å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒã€‚"""

                updated_state["qa_response"] = fallback_response
                updated_state["final_answer"] = f"é”™è¯¯æ¢å¤: {fallback_response}"
                updated_state["current_step"] = "error_handled"
                updated_state["is_complete"] = True

                if "messages" not in updated_state:
                    updated_state["messages"] = []
                updated_state["messages"].append(
                    {"role": "assistant", "content": fallback_response}
                )
                
                return Command(
                    update=updated_state,
                    goto="__end__"
                )

    except Exception as e:
        # é”™è¯¯æ¢å¤èŠ‚ç‚¹æœ¬èº«å‡ºé”™ï¼Œç›´æ¥æ ‡è®°å®Œæˆ
        error_state = state.copy()
        error_state["final_answer"] = "ç³»ç»Ÿé‡åˆ°ä¸¥é‡é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        error_state["qa_response"] = "è‡´å‘½é”™è¯¯: ç³»ç»Ÿé‡åˆ°ä¸¥é‡é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        error_state["current_step"] = "fatal_error"
        error_state["is_complete"] = True
        return Command(
             update=error_state,
             goto="__end__"
         )


# code_generator_command_nodeå·²åˆ é™¤ - åœ¨builder.pyä¸­æœªä½¿ç”¨


@track_node_execution("task_selector")
def task_selector_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """
    ä»»åŠ¡é€‰æ‹©èŠ‚ç‚¹ - Commandè¯­æ³•å®ç°
    æ ¹æ®ç”¨æˆ·è¾“å…¥é€‰æ‹©å…·ä½“çš„ä»»åŠ¡ç±»å‹å¹¶ç›´æ¥è·¯ç”±
    """
    try:
        user_input = state["user_input"]
        user_type = state.get("user_type", "amateur")
        
        # æ£€æŸ¥æ˜¯å¦æ¥è‡ªuser_choice_handlerï¼Œå¦‚æœæ˜¯åˆ™æ ¹æ®åŸå§‹é—®é¢˜é€‰æ‹©ä»»åŠ¡ç±»å‹
        if state.get("from_user_choice", False):
            # ä»æ‰§è¡Œå†å²ä¸­æ‰¾åˆ°åŸå§‹é—®é¢˜
            execution_history = state.get("execution_history", [])
            original_question = None
            for entry in reversed(execution_history):
                if (entry.get("node") in ["identity_check_command_node", "qa_agent_command_node"] and 
                    entry.get("action") in ["process_user_input", "generate_qa_response"] and
                    entry.get("input") and 
                    entry.get("input").lower() not in ["æ˜¯", "y", "yes", "è¦", "éœ€è¦", "1", "å¦", "n", "no", "ä¸è¦", "ä¸éœ€è¦", "0"]):
                    original_question = entry.get("input")
                    break
            
            if original_question:
                user_input = original_question
            else:
                user_input = state["user_input"]
        else:
            # è·å–LLMå®ä¾‹
            llm = get_llm_by_type("basic")

            # ä½¿ç”¨promptæ¨¡æ¿è·å–ä»»åŠ¡é€‰æ‹©æç¤ºè¯
            try:
                task_prompt_content = get_prompt("task_selection", 
                                               user_input=user_input, 
                                               user_type=user_type)
                task_prompt = ChatPromptTemplate.from_template(task_prompt_content)
            except Exception as e:
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¾èµ–promptæ¨¡æ¿
                task_prompt = None

            # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œä»»åŠ¡ç±»å‹è¯†åˆ« - å®Œå…¨ä¾èµ–LLMåˆ¤æ–­
            if llm:  # {user_input} ä¼šè¢«Pythonè§£é‡Šå™¨ç«‹å³æ›¿æ¢ä¸º user_input å˜é‡çš„å®é™…å€¼
                task_prompt = f"""è¯·ä»”ç»†åˆ†æä»¥ä¸‹ä¸“ä¸šç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«å…·ä½“çš„ä»»åŠ¡ç±»å‹ã€‚

ç”¨æˆ·è¾“å…¥: {user_input}

ä»»åŠ¡ç±»å‹å®šä¹‰ï¼š
- classification: å¤©ä½“åˆ†ç±»ä»»åŠ¡ï¼ˆè¯†åˆ«å¤©ä½“ç±»å‹ï¼‰
  ä¾‹å¦‚ï¼š"è¿™æ˜¯å“ªç§å¤©ä½“ï¼Ÿ"ã€"M87å±äºä»€ä¹ˆç±»å‹ï¼Ÿ"ã€"åˆ†ç±»è¿™ä¸ªå¤©ä½“"ã€"è¯†åˆ«å¤©ä½“ç±»å‹"
  
- retrieval: æ•°æ®æ£€ç´¢ä»»åŠ¡ï¼ˆè·å–å’Œåˆ†ææ•°æ®ï¼‰
  ä¾‹å¦‚ï¼š"åˆ†æM87çš„å°„ç”µæ˜Ÿç³»ç‰¹å¾"ã€"è·å–æ˜Ÿç³»æ•°æ®"ã€"æŸ¥è¯¢SDSSæ•°æ®"ã€"æ£€ç´¢å¤©ä½“ä¿¡æ¯"ã€"åˆ†æå¤©ä½“ç‰¹å¾"ã€"ç ”ç©¶å¤©ä½“æ€§è´¨"ã€"M31æ˜¯ä»€ä¹ˆ"ã€"M31çš„å‚è€ƒæ–‡çŒ®"ã€"M31çš„ç‰¹å¾"ã€"M31çš„æ€§è´¨"ã€"M31ç›¸å…³æ–‡çŒ®"ã€"ç¦»M31æœ€è¿‘çš„æ˜Ÿç³»æœ‰å“ªäº›"ã€"æä¾›åæ ‡åˆ¤æ–­æ˜Ÿç³»"
  
- visualization: ç»˜åˆ¶å›¾è¡¨ä»»åŠ¡ï¼ˆç”Ÿæˆå›¾åƒå’Œå›¾è¡¨ï¼‰
  ä¾‹å¦‚ï¼š"ç»˜åˆ¶å¤©ä½“ä½ç½®å›¾"ã€"ç”Ÿæˆå…‰è°±å›¾"ã€"å¯è§†åŒ–æ•°æ®"ã€"åˆ›å»ºå›¾è¡¨"ã€"åˆ¶ä½œå›¾åƒ"ã€"ç»˜åˆ¶åˆ†å¸ƒå›¾"

- multimark: å›¾ç‰‡è¯†åˆ«æ ‡æ³¨ä»»åŠ¡ï¼ˆåˆ†æå¤©æ–‡å›¾åƒå¹¶æ ‡æ³¨ï¼‰
  ä¾‹å¦‚ï¼š"æ ‡æ³¨è¿™å¼ æ˜Ÿç³»å›¾åƒ"ã€"è¯†åˆ«å›¾åƒä¸­çš„å¤©ä½“"ã€"æ ‡è®°å›¾åƒä¸­çš„å¯¹è±¡"ã€"å›¾åƒæ ‡æ³¨"ã€"è¯†åˆ«ç…§ç‰‡ä¸­çš„å¤©ä½“"ã€"è®­ç»ƒæ¨¡å‹"ã€"æ ‡æ³¨å›¾ç‰‡"ã€"è®­ç»ƒCNNæ¨¡å‹"ã€"è®­ç»ƒç¥ç»ç½‘ç»œ"ã€"æœºå™¨å­¦ä¹ "ã€"æ·±åº¦å­¦ä¹ "ã€"æ¨¡å‹è®­ç»ƒ"ã€"å¹¶è¡Œè®­ç»ƒ"ã€"è®­ç»ƒå¤šä¸ªæ¨¡å‹"

å…³é”®åŒºåˆ«ï¼š
- classification: é—®"æ˜¯ä»€ä¹ˆç±»å‹"ã€"å±äºä»€ä¹ˆåˆ†ç±»"
- retrieval: é—®"åˆ†æç‰¹å¾"ã€"ç ”ç©¶æ€§è´¨"ã€"è·å–æ•°æ®"ã€"æä¾›åæ ‡"ã€"æ˜Ÿç³»çš„å‚è€ƒæ–‡çŒ®"ã€"æä¾›ç‰¹å¾"ã€"æä¾›æ€§è´¨"ã€"æä¾›æœ€è¿‘çš„æ˜Ÿç³»"ã€"åˆ†ææ˜Ÿç³»åæ ‡"
- visualization: é—®"ç»˜åˆ¶"ã€"ç”Ÿæˆå›¾è¡¨"ã€"å¯è§†åŒ–"
- multimark: é—®"è®­ç»ƒ"ã€"è®­ç»ƒæ¨¡å‹"ã€"åˆ†æç…§ç‰‡"ã€"æ ‡è®°å›¾åƒ"ã€"æ ‡æ³¨å›¾ç‰‡"ã€"è®­ç»ƒCNN"ã€"è®­ç»ƒç¥ç»ç½‘ç»œ"ã€"æœºå™¨å­¦ä¹ "ã€"æ·±åº¦å­¦ä¹ "ã€"å¹¶è¡Œè®­ç»ƒ"

è¯·ä»”ç»†åˆ†æç”¨æˆ·çš„å…·ä½“éœ€æ±‚ï¼Œç„¶ååªè¿”å›ï¼šclassificationã€retrievalã€visualization æˆ– multimark
"""
                
                from langchain_core.messages import HumanMessage
                messages = [HumanMessage(content=task_prompt)] 
                response = llm.invoke(messages)
                task_type = response.content.strip().lower()
                
                # éªŒè¯å“åº”
                if task_type not in ["classification", "retrieval", "visualization", "multimark"]:
                    # å¦‚æœLLMè¿”å›çš„ä¸æ˜¯é¢„æœŸæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
                    if "classification" in task_type or "åˆ†ç±»" in task_type:
                        task_type = "classification"
                    elif "retrieval" in task_type or "æ£€ç´¢" in task_type or "æ•°æ®" in task_type:
                        task_type = "retrieval"
                    elif "visualization" in task_type or "å¯è§†åŒ–" in task_type or "å›¾è¡¨" in task_type:
                        task_type = "visualization"
                    elif "multimark" in task_type or "æ ‡æ³¨" in task_type or "å›¾åƒ" in task_type or "å›¾ç‰‡" in task_type or "è®­ç»ƒ" in task_type or "è®­ç»ƒæ¨¡å‹" in task_type:
                        task_type = "multimark"
                    else:
                        task_type = "classification"  # é»˜è®¤ä¸ºåˆ†ç±»ä»»åŠ¡
            else:
                # å¦‚æœLLMä¸å¯ç”¨ï¼ŒæŠ¥é”™è€Œä¸æ˜¯ä½¿ç”¨å…³é”®è¯åˆ¤æ–­
                raise Exception("LLMæœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œä»»åŠ¡ç±»å‹è¯†åˆ«")
            
            updated_state = state.copy()

        # æ›´æ–°çŠ¶æ€
        updated_state = state.copy()
        updated_state["task_type"] = task_type
        updated_state["selected_task_type"] = task_type  # ä¸ºäº†å…¼å®¹æµ‹è¯•
        updated_state["current_step"] = "task_selected"
        updated_state["confidence"] = 0.8  # åŸºäºè§„åˆ™çš„ç½®ä¿¡åº¦
        
        # æ¸…é™¤ä¸´æ—¶æ ‡è®°ï¼Œé¿å…å½±å“åç»­æµç¨‹
        if "from_user_choice" in updated_state:
            del updated_state["from_user_choice"]
        if "default_task_type" in updated_state:
            del updated_state["default_task_type"]
        
        # è®°å½•æ‰§è¡Œå†å²
        execution_history = updated_state.get("execution_history", [])
        execution_history.append({
            "node": "task_selector",
            "action": task_type,
            "input": user_input,
            "output": task_type,
            "timestamp": time.time()
        })
        updated_state["execution_history"] = execution_history
        
        # è·¯ç”±é€»è¾‘ - å››ä¸ªä¸»è¦ä»»åŠ¡ç±»å‹
        if task_type == "classification":
            return Command(
                update=updated_state,
                goto="classification_config"
            )
        elif task_type == "retrieval":
            return Command(
                update=updated_state,
                goto="data_retrieval"
            )
        elif task_type == "visualization":
            return Command(
                update=updated_state,
                goto="visualization"
            )
        elif task_type == "multimark":
            return Command(
                update=updated_state,
                goto="multimark"
            )
        else:
            # é»˜è®¤åˆ†ç±»ä»»åŠ¡
            updated_state["task_type"] = "classification"
            return Command(
                update=updated_state,
                goto="classification_config"
            )

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_state = state.copy()
        error_state["error_info"] = {
            "node": "task_selector_command_node",
            "error": str(e),
            "timestamp": time.time(),
        }
        error_state["retry_count"] = error_state.get("retry_count", 0) + 1
        
        return Command(
            update=error_state,
            goto="error_recovery"
        )


@track_node_execution("data_retrieval")
def data_retrieval_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """
    æ•°æ®æ£€ç´¢èŠ‚ç‚¹ - å¤„ç†ä¸“ä¸šç”¨æˆ·çš„æ•°æ®æ£€ç´¢ä»»åŠ¡
    """
    try:
        user_input = state["user_input"]
        
        # å¯¼å…¥MCPæ£€ç´¢å®¢æˆ·ç«¯
        try:
            from ..mcp_retrieval.client import query_astro_data
        except ImportError as e:
            logger.error(f"æ— æ³•å¯¼å…¥MCPæ£€ç´¢å®¢æˆ·ç«¯: {e}")
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            updated_state = state.copy()
            updated_state["current_step"] = "data_retrieval_completed"
            updated_state["is_complete"] = True
            updated_state["final_answer"] = f"æ•°æ®æ£€ç´¢åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ã€‚\n\næ‚¨çš„è¯·æ±‚ï¼š{user_input}\n\né”™è¯¯ä¿¡æ¯ï¼š{str(e)}\n\nè¯·æ£€æŸ¥MCPæ£€ç´¢æ¨¡å—æ˜¯å¦æ­£ç¡®å®‰è£…ã€‚"
            
            # è®°å½•æ‰§è¡Œå†å²
            execution_history = updated_state.get("execution_history", [])
            execution_history.append({
                "node": "data_retrieval_command_node",
                "action": "import_error",
                "input": user_input,
                "output": f"å¯¼å…¥é”™è¯¯: {str(e)}",
                "timestamp": time.time()
            })
            updated_state["execution_history"] = execution_history
            
            return Command(
                update=updated_state,
                goto="__end__"
            )
        
        # ä½¿ç”¨MCPæ£€ç´¢å®¢æˆ·ç«¯æ‰§è¡ŒæŸ¥è¯¢
        logger.info(f"ğŸ” å¼€å§‹æ‰§è¡Œæ•°æ®æ£€ç´¢æŸ¥è¯¢: {user_input}")
        
        try:
            # è°ƒç”¨MCPæ£€ç´¢å®¢æˆ·ç«¯
            retrieval_result = query_astro_data(user_input)
            logger.info("âœ… æ•°æ®æ£€ç´¢æŸ¥è¯¢å®Œæˆ")
            
            # æ„å»ºæœ€ç»ˆç­”æ¡ˆ
            final_answer = f"ğŸ” **æ•°æ®æ£€ç´¢ç»“æœ**\n\n"
            final_answer += f"**æŸ¥è¯¢å†…å®¹**: {user_input}\n\n"
            final_answer += f"**æ£€ç´¢ç»“æœ**:\n{retrieval_result}\n\n"
            final_answer += "---\n"
            final_answer += "ğŸ“Š **æ•°æ®æ¥æº**: SIMBAD TAPæœåŠ¡\n"
            final_answer += "ğŸ› ï¸ **æ£€ç´¢å·¥å…·**: MCPæ£€ç´¢å®¢æˆ·ç«¯\n"
            final_answer += "âœ¨ **åŠŸèƒ½ç‰¹ç‚¹**: æ”¯æŒå¤©ä½“åŸºç¡€ä¿¡æ¯ã€æ–‡çŒ®æŸ¥è¯¢ã€åæ ‡æœç´¢"
            
        except Exception as query_error:
            logger.error(f"æ•°æ®æ£€ç´¢æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {query_error}")
            final_answer = f"âŒ **æ•°æ®æ£€ç´¢å¤±è´¥**\n\n"
            final_answer += f"**æŸ¥è¯¢å†…å®¹**: {user_input}\n\n"
            final_answer += f"**é”™è¯¯ä¿¡æ¯**: {str(query_error)}\n\n"
            final_answer += "è¯·æ£€æŸ¥ï¼š\n"
            final_answer += "- ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n"
            final_answer += "- SIMBAD TAPæœåŠ¡æ˜¯å¦å¯ç”¨\n"
            final_answer += "- æŸ¥è¯¢æ ¼å¼æ˜¯å¦æ­£ç¡®\n\n"
            final_answer += "ğŸ’¡ **å»ºè®®**: å°è¯•ä½¿ç”¨å¤©ä½“åç§°ï¼ˆå¦‚M13ã€Vegaï¼‰æˆ–åæ ‡è¿›è¡ŒæŸ¥è¯¢"
        
        # æ›´æ–°çŠ¶æ€
        updated_state = state.copy()
        updated_state["current_step"] = "data_retrieval_completed"
        updated_state["is_complete"] = True
        updated_state["final_answer"] = final_answer
        updated_state["task_type"] = "data_retrieval"
        
        # è®°å½•æ‰§è¡Œå†å²
        execution_history = updated_state.get("execution_history", [])
        execution_history.append({
            "node": "data_retrieval_command_node",
            "action": "mcp_data_retrieval",
            "input": user_input,
            "output": final_answer,
            "timestamp": time.time(),
            "details": {
                "retrieval_success": "error" not in final_answer.lower(),
                "result_length": len(final_answer)
            }
        })
        updated_state["execution_history"] = execution_history

        return Command(
            update=updated_state,
            goto="__end__"
        )

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_state = state.copy()
        error_state["error_info"] = {
            "node": "data_retrieval_command_node",
            "error": str(e),
            "timestamp": time.time(),
        }
        error_state["final_answer"] = f"æ•°æ®æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        error_state["is_complete"] = True
        
        return Command(
            update=error_state,
            goto="__end__"
        )


@track_node_execution("visualization")
def visualization_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """
    å¯è§†åŒ–èŠ‚ç‚¹ - æ”¯æŒå¤šè½®å¯¹è¯çš„å¯è§†åŒ–éœ€æ±‚åˆ†æå’Œå›¾è¡¨ç»˜åˆ¶
    æ–°å®ç°ï¼šé›†æˆ Planner å¤šè½®å¯¹è¯ â†’ Coder â†’ Explainer å®Œæ•´æµç¨‹
    """
    try:
        user_input = state["user_input"]
        
        # å¯¼å…¥ Planner æ¨¡å—
        try:
            from src.planner import PlannerWorkflow
            from src.planner.dataset_manager import DatasetManager
            import os
            from pathlib import Path
            
            # è®¾ç½®æ­£ç¡®çš„æ•°æ®é›†ç›®å½•è·¯å¾„
            current_file = Path(__file__).resolve()
            astro_insight_root = current_file.parents[2]  # ä» src/graph/nodes.py åˆ° Astro-Insight-0913v3
            dataset_dir = astro_insight_root / "dataset"
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®© DatasetManager ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
            os.environ["ASTRO_DATASET_DIR"] = str(dataset_dir)
            
        except Exception as e:
            # å…³é”®ä¾èµ–ç¼ºå¤±æ—¶çš„å‹å¥½é™çº§
            updated_state = state.copy()
            updated_state["current_step"] = "visualization_failed"
            updated_state["is_complete"] = True
            updated_state["final_answer"] = (
                f"âŒ å¯è§†åŒ–æµç¨‹åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}\n\n"
                "è¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦å®Œæ•´ï¼š\n"
                "- src/planner æ¨¡å—å¯ç”¨\n- Coder/Explainer å­æ¨¡å—å®‰è£…æ— è¯¯\n"
                "- ä¾èµ–åº“ï¼ˆpandasã€numpyã€matplotlib ç­‰ï¼‰å·²å®‰è£…\n"
            )
            updated_state["task_type"] = "visualization"
            execution_history = updated_state.get("execution_history", [])
            execution_history.append({
                "node": "visualization_command_node",
                "action": "init_failed",
                "input": user_input,
                "output": str(e),
                "timestamp": time.time()
            })
            updated_state["execution_history"] = execution_history
            return Command(update=updated_state, goto="__end__")

        # åˆå§‹åŒ–å¤šè½®å¯¹è¯çŠ¶æ€
        if not state.get("visualization_session_id"):
            # é˜¶æ®µ1ï¼šåˆ›å»ºäº¤äº’å¼ä¼šè¯
            print("ğŸ”„ åˆå§‹åŒ–å¯è§†åŒ–éœ€æ±‚åˆ†æä¼šè¯...")
            planner = PlannerWorkflow()
            
            # åˆ›å»ºä¼šè¯
            session = planner.run_interactive_session(user_input)
            if not session["success"]:
                updated_state = state.copy()
                updated_state["current_step"] = "visualization_failed"
                updated_state["is_complete"] = True
                updated_state["task_type"] = "visualization"
                updated_state["final_answer"] = (
                    f"âŒ å¯è§†åŒ–ä¼šè¯åˆ›å»ºå¤±è´¥ï¼š{session.get('error')}\n\n"
                    "è¯·æ£€æŸ¥ Planner æ¨¡å—é…ç½®æˆ–ç¨åé‡è¯•ã€‚"
                )
                return Command(update=updated_state, goto="__end__")
            
            session_id = session["session_id"]
            print(f"âœ… å¯è§†åŒ–ä¼šè¯åˆ›å»ºæˆåŠŸ: {session_id}")
            
            # å¤„ç†åˆå§‹éœ€æ±‚
            print("ğŸ”„ å¤„ç†åˆå§‹å¯è§†åŒ–éœ€æ±‚...")
            result = planner.continue_interactive_session(session_id, user_input)
            
            if not result["success"]:
                updated_state = state.copy()
                updated_state["current_step"] = "visualization_failed"
                updated_state["is_complete"] = True
                updated_state["task_type"] = "visualization"
                updated_state["final_answer"] = (
                    f"âŒ åˆå§‹éœ€æ±‚å¤„ç†å¤±è´¥ï¼š{result.get('error')}\n\n"
                    "è¯·é‡æ–°æè¿°æ‚¨çš„å¯è§†åŒ–éœ€æ±‚ã€‚"
                )
                return Command(update=updated_state, goto="__end__")
            
            # ä¿å­˜ä¼šè¯çŠ¶æ€å¹¶è¿”å›æ¾„æ¸…é—®é¢˜
            updated_state = state.copy()
            updated_state["visualization_session_id"] = session_id
            updated_state["visualization_dialogue_state"] = "started"
            updated_state["visualization_turn_count"] = 1
            updated_state["visualization_max_turns"] = 8
            updated_state["visualization_dialogue_history"] = []
            updated_state["task_type"] = "visualization"
            
            # æ˜¾ç¤ºç³»ç»Ÿå›å¤
            if result.get("assistant_response"):
                print(f"\nğŸ¤– ç³»ç»Ÿå›å¤:")
                print(f"   {result['assistant_response']}")
                updated_state["visualization_dialogue_history"].append({
                    "turn": 1,
                    "user_input": user_input,
                    "assistant_response": result["assistant_response"],
                    "timestamp": time.time()
                })
            
            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            if result.get("current_status"):
                status = result["current_status"]
                print(f"\nğŸ“Š å½“å‰çŠ¶æ€:")
                print(f"   å¯¹è¯è½®æ¬¡: {status.get('current_turn', 0)}/{status.get('max_turns', 10)}")
                print(f"   çŠ¶æ€: {status.get('dialogue_status', 'unknown')}")
                
                if status.get("task_steps"):
                    print(f"   å·²è§„åˆ’ä»»åŠ¡: {len(status['task_steps'])}ä¸ª")
                    for i, step in enumerate(status['task_steps'][:3], 1):
                        print(f"     {i}. {step.get('description', 'N/A')}")
                
                if status.get("selected_dataset"):
                    print(f"   é€‰å®šæ•°æ®é›†: {status['selected_dataset'].get('name', 'unknown')}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤
            if result.get("needs_confirmation"):
                print(f"\nâ“ ç³»ç»Ÿéœ€è¦ç¡®è®¤:")
                print(f"   {result['confirmation_request']}")
                updated_state["awaiting_user_choice"] = True
                updated_state["current_visualization_request"] = result["confirmation_request"]
                updated_state["current_step"] = "visualization_clarifying"
                return Command(update=updated_state, goto="__end__")
            
            # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
            if result.get("completed"):
                print("\nğŸ‰ éœ€æ±‚è§„åˆ’å·²å®Œæˆ!")
                # ç›´æ¥æ‰§è¡Œ Pipeline
                return _execute_visualization_pipeline(updated_state, planner, session_id, result)
            
            # éœ€è¦ç»§ç»­æ¾„æ¸… - è¿”å›ç­‰å¾…ç”¨æˆ·è¾“å…¥çš„çŠ¶æ€
            updated_state["awaiting_user_choice"] = True
            updated_state["current_visualization_request"] = "è¯·ç»§ç»­æä¾›æ›´å¤šç»†èŠ‚æ¥å®Œå–„æ‚¨çš„å¯è§†åŒ–éœ€æ±‚"
            updated_state["current_step"] = "visualization_clarifying"
            updated_state["visualization_dialogue_state"] = "clarifying"
            
            return Command(update=updated_state, goto="__end__")
        
        # é˜¶æ®µ2ï¼šç»§ç»­å¤šè½®å¯¹è¯
        elif state.get("awaiting_user_choice") and state.get("visualization_dialogue_state") == "clarifying":
            session_id = state["visualization_session_id"]
            turn_count = state.get("visualization_turn_count", 1)
            max_turns = state.get("visualization_max_turns", 8)
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è½®æ¬¡
            if turn_count >= max_turns:
                print(f"\nâš ï¸ å·²è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ¬¡é™åˆ¶ ({max_turns}è½®)")
                print("ğŸ”„ è‡ªåŠ¨å®Œæˆéœ€æ±‚è§„åˆ’å¹¶æ‰§è¡ŒPipeline...")
                planner = PlannerWorkflow()
                return _execute_visualization_pipeline(state, planner, session_id, None)
            
            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ['done', 'å®Œæˆ', 'ç¡®è®¤', 'æ‰§è¡Œ']:
                print("âœ… ç”¨æˆ·ç¡®è®¤éœ€æ±‚å®Œæˆ")
                planner = PlannerWorkflow()
                return _execute_visualization_pipeline(state, planner, session_id, None)
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q', 'å–æ¶ˆ']:
                print("ğŸ‘‹ ç”¨æˆ·é€€å‡ºå¯è§†åŒ–å¯¹è¯")
                updated_state = state.copy()
                updated_state["current_step"] = "visualization_cancelled"
                updated_state["is_complete"] = True
                updated_state["task_type"] = "visualization"
                updated_state["final_answer"] = "å¯è§†åŒ–éœ€æ±‚åˆ†æå·²å–æ¶ˆã€‚"
                return Command(update=updated_state, goto="__end__")
            
            print(f"\nğŸ‘¤ ç”¨æˆ· (ç¬¬{turn_count}è½®): {user_input}")
            
            # ç»§ç»­ä¼šè¯
            planner = PlannerWorkflow()
            result = planner.continue_interactive_session(session_id, user_input)
            
            if not result["success"]:
                print(f"âŒ å¯¹è¯å¤±è´¥: {result.get('error')}")
                updated_state = state.copy()
                updated_state["current_step"] = "visualization_failed"
                updated_state["is_complete"] = True
                updated_state["task_type"] = "visualization"
                updated_state["final_answer"] = f"å¯è§†åŒ–å¯¹è¯å¤±è´¥ï¼š{result.get('error')}"
                return Command(update=updated_state, goto="__end__")
            
            # æ›´æ–°å¯¹è¯å†å²
            dialogue_history = state.get("visualization_dialogue_history", [])
            dialogue_history.append({
                "turn": turn_count,
                "user_input": user_input,
                "assistant_response": result.get("assistant_response", ""),
                "timestamp": time.time()
            })
            
            # æ˜¾ç¤ºç³»ç»Ÿå›å¤
            if result.get("assistant_response"):
                print(f"\nğŸ¤– ç³»ç»Ÿå›å¤:")
                print(f"   {result['assistant_response']}")
            
            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            if result.get("current_status"):
                status = result["current_status"]
                print(f"\nğŸ“Š å½“å‰çŠ¶æ€:")
                print(f"   å¯¹è¯è½®æ¬¡: {status.get('current_turn', 0)}/{status.get('max_turns', 10)}")
                print(f"   çŠ¶æ€: {status.get('dialogue_status', 'unknown')}")
                
                if status.get("task_steps"):
                    print(f"   å·²è§„åˆ’ä»»åŠ¡: {len(status['task_steps'])}ä¸ª")
                    for i, step in enumerate(status['task_steps'][:3], 1):
                        print(f"     {i}. {step.get('description', 'N/A')}")
                
                if status.get("selected_dataset"):
                    print(f"   é€‰å®šæ•°æ®é›†: {status['selected_dataset'].get('name', 'unknown')}")
            
            updated_state = state.copy()
            updated_state["visualization_turn_count"] = turn_count + 1
            updated_state["visualization_dialogue_history"] = dialogue_history
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤
            if result.get("needs_confirmation"):
                print(f"\nâ“ ç³»ç»Ÿéœ€è¦ç¡®è®¤:")
                print(f"   {result['confirmation_request']}")
                updated_state["awaiting_user_choice"] = True
                updated_state["current_visualization_request"] = result["confirmation_request"]
                updated_state["current_step"] = "visualization_clarifying"
                return Command(update=updated_state, goto="__end__")
            
            # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
            if result.get("completed"):
                print("\nğŸ‰ éœ€æ±‚è§„åˆ’å·²å®Œæˆ!")
                return _execute_visualization_pipeline(updated_state, planner, session_id, result)
            
            # ç»§ç»­æ¾„æ¸…
            updated_state["awaiting_user_choice"] = True
            updated_state["current_visualization_request"] = "è¯·ç»§ç»­æä¾›æ›´å¤šç»†èŠ‚æ¥å®Œå–„æ‚¨çš„å¯è§†åŒ–éœ€æ±‚"
            updated_state["current_step"] = "visualization_clarifying"
            
            return Command(update=updated_state, goto="__end__")
        
        else:
            # å¼‚å¸¸çŠ¶æ€ï¼Œé‡ç½®
            updated_state = state.copy()
            updated_state["current_step"] = "visualization_failed"
            updated_state["is_complete"] = True
            updated_state["task_type"] = "visualization"
            updated_state["final_answer"] = "å¯è§†åŒ–å¯¹è¯çŠ¶æ€å¼‚å¸¸ï¼Œè¯·é‡æ–°å¼€å§‹ã€‚"
            return Command(update=updated_state, goto="__end__")

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_state = state.copy()
        error_state["error_info"] = {
            "node": "visualization_command_node",
            "error": str(e),
            "timestamp": time.time(),
        }
        error_state["final_answer"] = (
            f"å›¾è¡¨ç»˜åˆ¶è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸé”™è¯¯ï¼š{str(e)}\n\n"
            "è¯·ç¨åé‡è¯•ï¼Œæˆ–ç®€åŒ–è¯·æ±‚å†…å®¹ã€‚"
        )
        error_state["is_complete"] = True
        error_state["task_type"] = "visualization"
        return Command(update=error_state, goto="__end__")


def _execute_visualization_pipeline(state: AstroAgentState, planner, session_id: str, result=None) -> Command[AstroAgentState]:
    """æ‰§è¡Œå®Œæ•´çš„å¯è§†åŒ– Pipeline"""
    try:
        print("\nğŸ”„ æ‰§è¡Œå®Œæ•´å¯è§†åŒ–Pipeline...")
        
        # è·å–æœ€ç»ˆéœ€æ±‚
        if result and result.get("final_result"):
            final_request = result["final_result"].final_prompt or result["final_result"].user_initial_request
        else:
            final_request = state["user_input"]
        
        # æ‰§è¡Œå®Œæ•´ Pipeline
        pipeline_result = planner.run_complete_pipeline(
            user_request=final_request,
            session_id=session_id,
            explanation_type="detailed"
        )
        
        # å¤±è´¥è·¯å¾„ï¼šè¿”å›æ¸…æ™°çš„é”™è¯¯ä¸å»ºè®®
        if not pipeline_result.get("success"):
            error_msg = pipeline_result.get("error", "æœªçŸ¥é”™è¯¯")
            error_type = pipeline_result.get("error_type", "unknown")
            updated_state = state.copy()
            updated_state["current_step"] = "visualization_failed"
            updated_state["is_complete"] = True
            updated_state["task_type"] = "visualization"
            updated_state["final_answer"] = (
                f"âŒ å¯è§†åŒ–Pipelineæ‰§è¡Œå¤±è´¥ ({error_type})\n\n"
                f"è¯·æ±‚ï¼š{final_request}\n"
                f"é”™è¯¯ä¿¡æ¯ï¼š{error_msg}\n\n"
                "å»ºè®®ï¼š\n- ç¡®è®¤ conf.yaml ä¸­æ¨¡å‹/å¯†é’¥é…ç½®\n"
                "- ç¡®ä¿ output/ ç›®å½•å¯å†™\n- é‡æ–°å°è¯•ç®€åŒ–çš„å¯è§†åŒ–éœ€æ±‚\n"
            )
            return Command(update=updated_state, goto="__end__")
        
        # æˆåŠŸè·¯å¾„ï¼šç»„è£…ç»“æœ
        coder_result = pipeline_result.get("coder_result", {})
        explainer_result = pipeline_result.get("explainer_result", {})
        
        generated_code = (
            coder_result.get("code") or
            coder_result.get("generated_code") or
            ""
        )
        generated_files = (
            pipeline_result.get("generated_files") or
            coder_result.get("generated_files") or
            []
        )
        stdout_text = str(coder_result.get("output", "")).strip()
        stderr_text = str(coder_result.get("error", "")).strip()
        
        # æ„å»º final_answerï¼ˆåŒ…å«æ–‡ä»¶åˆ—è¡¨ã€stdout/stderr æ‘˜è¦ä¸è§£é‡Šæ€»ç»“ï¼‰
        files_section = "æ— ç”Ÿæˆæ–‡ä»¶" if not generated_files else "\n".join([f"- {p}" for p in generated_files])
        stdout_section = stdout_text[:1200] if stdout_text else "(æ— è¾“å‡º)"
        stderr_section = stderr_text[:1200] if stderr_text else "(æ— é”™è¯¯)"
        
        explain_summary = ""
        if explainer_result.get("success"):
            summary = explainer_result.get("summary", "")
            insights = explainer_result.get("insights", [])
            top_insight = (insights[0] if insights else "")
            explain_summary = (
                (f"\n\nğŸ“ ç»“æœè§£é‡Šæ‘˜è¦ï¼š\n{summary}" if summary else "") +
                (f"\nğŸ” å…³é”®æ´å¯Ÿï¼š{top_insight}" if top_insight else "")
            )
        
        # æ·»åŠ å¯¹è¯å†å²åˆ°æœ€ç»ˆç»“æœ
        dialogue_summary = ""
        dialogue_history = state.get("visualization_dialogue_history", [])
        if dialogue_history:
            dialogue_summary = "\n\nğŸ’¬ éœ€æ±‚æ¾„æ¸…è¿‡ç¨‹ï¼š\n"
            for i, turn in enumerate(dialogue_history, 1):
                dialogue_summary += f"ç¬¬{i}è½®: {turn['user_input']}\n"
                dialogue_summary += f"ç³»ç»Ÿå›å¤: {turn['assistant_response'][:200]}...\n\n"
        
        final_answer = (
            "ğŸ‰ å¯è§†åŒ–æµç¨‹å®Œæˆï¼\n\n"
            f"è¯·æ±‚ï¼š{final_request}\n"
            f"ç”Ÿæˆæ–‡ä»¶ï¼ˆ{len(generated_files)}ï¼‰ï¼š\n{files_section}\n\n"
            "â€”â€” æ‰§è¡Œè¾“å‡ºï¼ˆstdoutï¼‰ â€”â€”\n"
            f"{stdout_section}\n\n"
            "â€”â€” é”™è¯¯ä¿¡æ¯ï¼ˆstderrï¼‰ â€”â€”\n"
            f"{stderr_section}"
            f"{explain_summary}"
            f"{dialogue_summary}"
        )
        
        # æ›´æ–°çŠ¶æ€
        updated_state = state.copy()
        updated_state["current_step"] = "visualization_completed"
        updated_state["is_complete"] = True
        updated_state["task_type"] = "visualization"
        updated_state["generated_code"] = generated_code
        if generated_files:
            updated_state["generated_files"] = generated_files
        updated_state["final_answer"] = final_answer
        updated_state["visualization_dialogue_state"] = "completed"
        updated_state["awaiting_user_choice"] = False
        
        # è®°å½•æ‰§è¡Œå†å²ï¼šplan â†’ code â†’ explain
        execution_history = updated_state.get("execution_history", [])
        execution_history.append({
            "node": "visualization_command_node",
            "action": "multi_turn_pipeline_completed",
            "input": final_request,
            "output": f"files={len(generated_files)}; stdout={len(stdout_text)}; stderr={len(stderr_text)}; turns={len(dialogue_history)}",
            "timestamp": time.time(),
            "details": {
                "planner_steps": len(pipeline_result.get("task_steps", [])),
                "execution_time_total": pipeline_result.get("total_processing_time"),
                "dialogue_turns": len(dialogue_history),
                "session_id": session_id
            }
        })
        updated_state["execution_history"] = execution_history
        
        print("âœ… å¯è§†åŒ–Pipelineæ‰§è¡ŒæˆåŠŸ!")
        print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶: {len(generated_files)}ä¸ª")
        print(f"ğŸ” è§£é‡Šæ•°é‡: {len(pipeline_result.get('explanations', []))}ä¸ª")
        print(f"ğŸ’¬ å¯¹è¯è½®æ¬¡: {len(dialogue_history)}è½®")
        
        return Command(update=updated_state, goto="__end__")
        
    except Exception as e:
        # Pipelineæ‰§è¡Œé”™è¯¯
        updated_state = state.copy()
        updated_state["current_step"] = "visualization_failed"
        updated_state["is_complete"] = True
        updated_state["task_type"] = "visualization"
        updated_state["final_answer"] = f"Pipelineæ‰§è¡Œå¤±è´¥ï¼š{str(e)}"
        updated_state["visualization_dialogue_state"] = "failed"
        return Command(update=updated_state, goto="__end__")


@track_node_execution("multimark")
def multimark_command_node(state: AstroAgentState) -> Command[AstroAgentState]:
    """
    å¤šæ¨¡æ€æ ‡æ³¨èŠ‚ç‚¹ - å¤„ç†å¤©æ–‡å›¾åƒçš„AIè¯†åˆ«å’Œæ ‡æ³¨ä»»åŠ¡
    ä½¿ç”¨MCP MLå®¢æˆ·ç«¯è°ƒç”¨mcp_mlæœåŠ¡å™¨
    """
    try:
        from pathlib import Path
        user_input = state["user_input"]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾åƒåˆ†ç±»è¯·æ±‚
        is_classification_request = any(keyword in user_input.lower() for keyword in [
            "åˆ†ç±»", "è¯†åˆ«", "æ ‡æ³¨", "åˆ†æ", "å›¾åƒ", "ç…§ç‰‡", "å›¾ç‰‡", "æ˜Ÿç³»", "å¤©ä½“", "è®­ç»ƒ", "æ¨¡å‹"
        ])
        
        if is_classification_request:
            # ä½¿ç”¨MCP MLå®¢æˆ·ç«¯è°ƒç”¨mcp_mlæœåŠ¡å™¨
            try:
                # åŠ¨æ€å¯¼å…¥MCP MLå®¢æˆ·ç«¯
                current_file = Path(__file__).resolve()
                astro_insight_root = current_file.parents[2]  # ä» src/graph/nodes.py åˆ° Astro-Insight-0913v3
                mcp_ml_dir = astro_insight_root / "src" / "mcp_ml"
                mcp_ml_output_dir = str(mcp_ml_dir / "output")
                
                # æ·»åŠ mcp_mlç›®å½•åˆ°Pythonè·¯å¾„
                import sys
                if str(mcp_ml_dir) not in sys.path:
                    sys.path.insert(0, str(mcp_ml_dir))
                
                from client import get_ml_client
                
                # è·å–MLå®¢æˆ·ç«¯
                ml_client = get_ml_client()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒæ¨¡å‹
                if any(keyword in user_input.lower() for keyword in ["è®­ç»ƒ", "train", "æ¨¡å‹", "model"]):
                    # ç›´æ¥è°ƒç”¨MCP MLæœåŠ¡å™¨çš„å‡½æ•°ï¼Œç»•è¿‡å¤æ‚çš„MCPåè®®
                    try:
                        import sys
                        import os
                        from datetime import datetime
                        from pathlib import Path
                        # åˆ‡æ¢åˆ°mcp_mlç›®å½•ï¼Œç¡®ä¿é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®
                        original_cwd = os.getcwd()
                        # è·å–æ­£ç¡®çš„mcp_mlè·¯å¾„
                        current_file = Path(__file__).resolve()
                        astro_insight_root = current_file.parents[2]  # ä» src/graph/nodes.py åˆ° Astro-Insight-0913v3
                        mcp_ml_dir = astro_insight_root / "src" / "mcp_ml"
                        os.chdir(str(mcp_ml_dir))
                        sys.path.insert(0, str(mcp_ml_dir))
                        
                        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¦æ±‚å¹¶è¡Œè®­ç»ƒå¤šä¸ªæ¨¡å‹
                        if any(keyword in user_input.lower() for keyword in ["å¤šä¸ª", "å¹¶è¡Œ", "åŒæ—¶", "æ‰¹é‡", "multiple", "parallel"]):
                            # ç›´æ¥è°ƒç”¨test_generate_and_run.pyä¸­çš„å‡½æ•°
                            from test_generate_and_run import test_generate_and_run
                            
                            # å‡†å¤‡ç”¨æˆ·æè¿°
                            if any(keyword in user_input.lower() for keyword in ["ç®€å•", "åŸºç¡€", "æ·±åº¦", "å¤æ‚", "è½»é‡", "heavy", "light", "simple", "complex"]):
                                # ç”¨æˆ·æä¾›äº†å…·ä½“çš„æ¨¡å‹æè¿°ï¼Œç›´æ¥ä½¿ç”¨
                                user_descriptions = user_input
                            else:
                                # ç”¨æˆ·æ²¡æœ‰æä¾›å…·ä½“æè¿°ï¼Œä½¿ç”¨é»˜è®¤çš„å¤šä¸ªé…ç½®
                                user_descriptions = "ç®€å•CNNæ¨¡å‹ï¼Œbatch_size=32ï¼Œepochs=4;åŸºç¡€CNNæ¨¡å‹ï¼Œbatch_size=16ï¼Œepochs=4;æ·±åº¦CNNæ¨¡å‹ï¼Œbatch_size=64ï¼Œepochs=4"
                            
                            logger.info(f"å¼€å§‹å¹¶è¡Œè®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œç”¨æˆ·éœ€æ±‚: {user_input}")
                            result = test_generate_and_run(user_descriptions)
                            
                            if result["status"] == "success":
                                final_answer = f"""ğŸš€ **å¹¶è¡ŒMLæ¨¡å‹è®­ç»ƒå®Œæˆ**

**çŠ¶æ€**: âœ… å¹¶è¡Œè®­ç»ƒæˆåŠŸå®Œæˆ

**è®­ç»ƒç»“æœ**:
- ç”Ÿæˆçš„é…ç½®æ–‡ä»¶: {len(result['generated_configs'])} ä¸ª
- å®éªŒä¼šè¯: {result.get('session_name', 'N/A')}
- æ€»è¿›ç¨‹æ•°: {result['experiment_results']['execution_summary']['total_processes']}
- æˆåŠŸè¿›ç¨‹: {result['experiment_results']['execution_summary']['successful_processes']}

**æ‚¨çš„è¯·æ±‚**: {user_input}

**æ¨¡å‹ä¿å­˜ä½ç½®**: {mcp_ml_output_dir} ç›®å½•ä¸‹

**ä¸‹ä¸€æ­¥**: æ‚¨å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„å¤šä¸ªæ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»å’Œæ ‡æ³¨"""
                            else:
                                final_answer = f"""âš ï¸ **å¹¶è¡ŒMLæ¨¡å‹è®­ç»ƒå¤±è´¥**

**é”™è¯¯ä¿¡æ¯**: {result.get('message', 'æœªçŸ¥é”™è¯¯')}

**æ‚¨çš„è¯·æ±‚**: {user_input}

**å»ºè®®**: ç¨åé‡è¯•æˆ–æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
                        else:
                            # ä½¿ç”¨å•ä¸ªæ¨¡å‹è®­ç»ƒåŠŸèƒ½
                            from server import run_pipeline
                            
                            logger.info(f"å¼€å§‹è®­ç»ƒå•ä¸ªæ¨¡å‹ï¼Œç”¨æˆ·éœ€æ±‚: {user_input}")
                            result = run_pipeline()
                            logger.info(f"MLè®­ç»ƒå®Œæˆ: {result}")
                            
                            final_answer = f"""ğŸš€ **MLæ¨¡å‹è®­ç»ƒå®Œæˆ**

**çŠ¶æ€**: âœ… è®­ç»ƒæˆåŠŸå®Œæˆ

**è®­ç»ƒç»“æœ**:
{result if result else "è®­ç»ƒå·²å®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜"}

**æ‚¨çš„è¯·æ±‚**: {user_input}

**æ¨¡å‹ä¿å­˜ä½ç½®**: {mcp_ml_output_dir} ç›®å½•ä¸‹

**ä¸‹ä¸€æ­¥**: æ‚¨å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»å’Œæ ‡æ³¨"""
                        
                        # æ¢å¤åŸå§‹å·¥ä½œç›®å½•
                        os.chdir(original_cwd)
                        
                    except Exception as e:
                        logger.error(f"ç›´æ¥è°ƒç”¨MCP MLæœåŠ¡å™¨å¤±è´¥: {str(e)}")
                        final_answer = f"""âš ï¸ **MLæ¨¡å‹è®­ç»ƒå¤±è´¥**

**é”™è¯¯ä¿¡æ¯**: {str(e)}

**æ‚¨çš„è¯·æ±‚**: {user_input}

**å»ºè®®**:
1. æ£€æŸ¥MCP MLæœåŠ¡å™¨æ˜¯å¦æ­£å¸¸è¿è¡Œ
2. ç¡®è®¤ä¾èµ–åŒ…å·²æ­£ç¡®å®‰è£…
3. ç¨åé‡è¯•"""
                    
                else:
                    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
                    final_answer = f"""ğŸ”­ **å¤šæ¨¡æ€æ ‡æ³¨åŠŸèƒ½**

**åŠŸèƒ½è¯´æ˜**:
- åŸºäºMCP MLæœåŠ¡å™¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹
- æ”¯æŒæ˜Ÿç³»å½¢æ€è‡ªåŠ¨åˆ†ç±»
- è¯†åˆ«æ¤­åœ†æ˜Ÿç³»ã€æ—‹æ¶¡æ˜Ÿç³»ã€ä¸è§„åˆ™æ˜Ÿç³»ç­‰ç±»å‹

**æœåŠ¡å™¨çŠ¶æ€**: âœ… MCP MLæœåŠ¡å™¨å¯ç”¨
**é…ç½®è·¯å¾„**: mcp_ml/config/config.yaml

**ä½¿ç”¨æ–¹æ³•**:
1. è®­ç»ƒæ¨¡å‹ï¼šè¯´"è®­ç»ƒæ¨¡å‹"æˆ–"å¼€å§‹è®­ç»ƒ"
2. å›¾åƒåˆ†ç±»ï¼šæä¾›å›¾åƒè·¯å¾„è¿›è¡Œåˆ†æ
3. æ¨¡å‹çŠ¶æ€ï¼šæŸ¥è¯¢å½“å‰æ¨¡å‹çŠ¶æ€

**æŠ€æœ¯ç‰¹ç‚¹**:
- ä½¿ç”¨CNNæ¶æ„è¿›è¡Œå›¾åƒåˆ†ç±»
- æ”¯æŒæ•°æ®å¢å¼ºå’Œé¢„å¤„ç†
- æä¾›è®­ç»ƒå†å²å¯è§†åŒ–
- ç”Ÿæˆæ··æ·†çŸ©é˜µå’Œæ€§èƒ½æŒ‡æ ‡

**æ”¯æŒçš„å›¾åƒæ ¼å¼**: JPG, JPEG, PNG, TIFF
**æ¨èå›¾åƒå°ºå¯¸**: 128x128åƒç´ 

æ‚¨çš„è¯·æ±‚ï¼š{user_input}"""
                
            except ImportError as e:
                final_answer = f"""âš ï¸ **å¤šæ¨¡æ€æ ‡æ³¨åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨**

**é”™è¯¯ä¿¡æ¯**: æ— æ³•å¯¼å…¥MCP MLå®¢æˆ·ç«¯ ({str(e)})

**å¯èƒ½åŸå› **:
- ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…ï¼ˆmcp, fastmcpç­‰ï¼‰
- æ¨¡å—æ–‡ä»¶ä¸å®Œæ•´

**å»ºè®®**:
1. å®‰è£…ä¾èµ–ï¼špip install mcp fastmcp
2. æ£€æŸ¥mcp_ml_clientæ¨¡å—æ–‡ä»¶æ˜¯å¦å®Œæ•´
3. ç¨åé‡è¯•

æ‚¨çš„è¯·æ±‚ï¼š{user_input}"""
            except Exception as e:
                final_answer = f"""âŒ **å¤šæ¨¡æ€æ ‡æ³¨å¤„ç†å¤±è´¥**

**é”™è¯¯ä¿¡æ¯**: {str(e)}

**å»ºè®®**: è¯·ç®€åŒ–è¯·æ±‚æˆ–ç¨åé‡è¯•

æ‚¨çš„è¯·æ±‚ï¼š{user_input}"""
        else:
            final_answer = f"""ğŸ”­ **å¤šæ¨¡æ€æ ‡æ³¨åŠŸèƒ½**

**æ”¯æŒçš„åŠŸèƒ½**:
1. **å¤©æ–‡å›¾åƒåˆ†ç±»** - è¯†åˆ«æ˜Ÿç³»ç±»å‹å’Œå½¢æ€
2. **å¤©ä½“ç‰¹å¾è¯†åˆ«** - åˆ†æå¤©ä½“çš„ç‰©ç†ç‰¹å¾
3. **å›¾åƒè´¨é‡è¯„ä¼°** - è¯„ä¼°è§‚æµ‹å›¾åƒçš„è´¨é‡
4. **è‡ªåŠ¨æ ‡æ³¨ç”Ÿæˆ** - ä¸ºå›¾åƒç”Ÿæˆç§‘å­¦æ ‡æ³¨
5. **æ¨¡å‹è®­ç»ƒ** - è®­ç»ƒæ–°çš„æ·±åº¦å­¦ä¹ æ¨¡å‹

**ä½¿ç”¨æ–¹æ³•**:
- æ¨¡å‹è®­ç»ƒï¼šè¯´"è®­ç»ƒæ¨¡å‹"æˆ–"å¼€å§‹è®­ç»ƒ"
- å›¾åƒåˆ†ç±»ï¼šæä¾›å›¾åƒè·¯å¾„ï¼Œå¦‚"åˆ†ç±»è¿™å¼ æ˜Ÿç³»å›¾åƒï¼špath/to/image.jpg"
- ç‰¹å¾è¯†åˆ«ï¼šæè¿°è¦åˆ†æçš„å¤©ä½“ç‰¹å¾
- è´¨é‡è¯„ä¼°ï¼šä¸Šä¼ å›¾åƒè¿›è¡Œè´¨é‡åˆ†æ

**æŠ€æœ¯ç‰¹ç‚¹**:
- åŸºäºMCP MLæœåŠ¡å™¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹
- æ”¯æŒå¤šç§å¤©æ–‡å›¾åƒæ ¼å¼
- æä¾›è¯¦ç»†çš„ç½®ä¿¡åº¦è¯„ä¼°
- é›†æˆå®Œæ•´çš„è®­ç»ƒå’Œæ¨ç†æµç¨‹

æ‚¨çš„è¯·æ±‚ï¼š{user_input}"""
        
        # æ›´æ–°çŠ¶æ€
        updated_state = state.copy()
        updated_state["current_step"] = "multimark_completed"
        updated_state["is_complete"] = True
        updated_state["final_answer"] = final_answer
        updated_state["task_type"] = "multimark"
        
        # è®°å½•æ‰§è¡Œå†å²
        execution_history = updated_state.get("execution_history", [])
        execution_history.append({
            "node": "multimark_command_node",
            "action": "mcp_ml_integration" if is_classification_request else "multimark_info",
            "input": user_input,
            "output": "å¤šæ¨¡æ€æ ‡æ³¨å¤„ç†å®Œæˆ",
            "timestamp": time.time()
        })
        updated_state["execution_history"] = execution_history

        return Command(
            update=updated_state,
            goto="__end__"
        )

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_state = state.copy()
        error_state["error_info"] = {
            "node": "multimark_command_node",
            "error": str(e),
            "timestamp": time.time(),
        }
        error_state["final_answer"] = f"å¤šæ¨¡æ€æ ‡æ³¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        error_state["is_complete"] = True
        
        return Command(
            update=error_state,
            goto="__end__"
        )


